{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72134a61",
   "metadata": {},
   "source": [
    "### Assistive Robotic Arm for Paralyzed Individuals Using Facial Gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d86b30d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial connection established.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import serial\n",
    "import time\n",
    "\n",
    "# Initialize serial communication with Arduino\n",
    "def initialize_serial(port, baud_rate=9600):\n",
    "    try:\n",
    "        arduino = serial.Serial(port, baud_rate)\n",
    "        time.sleep(2)  # Allow time for connection to initialize\n",
    "        print(\"Serial connection established.\")\n",
    "        return arduino\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing serial: {e}\")\n",
    "        return None\n",
    "\n",
    "# Initialize Mediapipe FaceMesh\n",
    "def initialize_face_mesh():\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    return mp_face_mesh.FaceMesh(refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Function to calculate gaze direction\n",
    "def calculate_gaze_direction(iris_center, eye_corners):\n",
    "    left_corner = eye_corners[0]\n",
    "    right_corner = eye_corners[1]\n",
    "    horizontal_ratio = (iris_center.x - left_corner.x) / (right_corner.x - left_corner.x)\n",
    "    return horizontal_ratio\n",
    "\n",
    "# Function to detect blinking\n",
    "def is_blinking(eye_landmarks, threshold=0.2):\n",
    "    top = np.array([eye_landmarks[1].x, eye_landmarks[1].y])\n",
    "    bottom = np.array([eye_landmarks[2].x, eye_landmarks[2].y])\n",
    "    left = np.array([eye_landmarks[0].x, eye_landmarks[0].y])\n",
    "    right = np.array([eye_landmarks[3].x, eye_landmarks[3].y])\n",
    "\n",
    "    vertical_distance = np.linalg.norm(top - bottom)\n",
    "    horizontal_distance = np.linalg.norm(left - right)\n",
    "\n",
    "    blink_ratio = vertical_distance / horizontal_distance\n",
    "    return blink_ratio < threshold\n",
    "\n",
    "# Function to detect mouth status\n",
    "def detect_mouth_status(landmarks):\n",
    "    upper_lip_y = landmarks.landmark[61].y\n",
    "    lower_lip_y = landmarks.landmark[17].y\n",
    "    lip_distance = abs(upper_lip_y - lower_lip_y)\n",
    "    \n",
    "    left_eye = landmarks.landmark[33]\n",
    "    right_eye = landmarks.landmark[263]\n",
    "    eye_distance = abs(left_eye.x - right_eye.x)\n",
    "    \n",
    "    threshold = 0.025 + (eye_distance * 0.1)\n",
    "    return \"Mouth Open\" if lip_distance > threshold else \"Mouth Closed\"\n",
    "\n",
    "# Function to calculate eyebrow movement\n",
    "def calculate_eyebrow_movement(landmarks, left_brow_indices, right_brow_indices, baseline, movement_threshold):\n",
    "    left_brow_y = np.mean([landmarks[i][1] for i in left_brow_indices])\n",
    "    right_brow_y = np.mean([landmarks[i][1] for i in right_brow_indices])\n",
    "    avg_brow_y = (left_brow_y + right_brow_y) / 2\n",
    "\n",
    "    if baseline is None:\n",
    "        baseline = avg_brow_y\n",
    "        return \"Neutral\", baseline\n",
    "\n",
    "    if avg_brow_y < baseline - movement_threshold:\n",
    "        return \"Eyebrows Raised\", baseline\n",
    "    else:\n",
    "        baseline = 0.9 * baseline + 0.1 * avg_brow_y\n",
    "        return \"Neutral\", baseline\n",
    "\n",
    "# Function to send commands to Arduino\n",
    "def send_command_to_arduino(arduino, command):\n",
    "    if arduino:\n",
    "        try:\n",
    "            arduino.write(f\"{command}\\n\".encode())\n",
    "        except Exception as e:\n",
    "            print(f\"Error sending command: {e}\")\n",
    "\n",
    "# Function to overlay detection results\n",
    "def overlay_text(frame, text, position, color=(0, 255, 0)):\n",
    "    cv2.putText(frame, text, position, cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2, cv2.LINE_AA)\n",
    "\n",
    "# Function to process face landmarks\n",
    "def process_face_landmarks(face_landmarks, arduino, baseline_position, movement_threshold, frame):\n",
    "    global blink_detected, claw_state\n",
    "    \n",
    "    LEFT_BROW = [46, 53, 52, 65, 55, 63, 105, 66, 107]\n",
    "    RIGHT_BROW = [276, 283, 282, 295, 285, 293, 334, 296, 336]\n",
    "    \n",
    "    # Gaze detection\n",
    "    left_iris = face_landmarks.landmark[468]\n",
    "    right_iris = face_landmarks.landmark[473]\n",
    "    left_eye_corners = [face_landmarks.landmark[33], face_landmarks.landmark[133]]\n",
    "    right_eye_corners = [face_landmarks.landmark[362], face_landmarks.landmark[263]]\n",
    "    \n",
    "    avg_gaze_ratio = (calculate_gaze_direction(left_iris, left_eye_corners) +\n",
    "                      calculate_gaze_direction(right_iris, right_eye_corners)) / 2\n",
    "    gaze_direction = \"Center\"\n",
    "    if avg_gaze_ratio < 0.35:\n",
    "        send_command_to_arduino(arduino, 'L')\n",
    "        gaze_direction = \"Left\"\n",
    "        gaze_color = (0, 0, 255)  # Red\n",
    "    elif avg_gaze_ratio > 0.65:\n",
    "        send_command_to_arduino(arduino, 'R')\n",
    "        gaze_direction = \"Right\"\n",
    "        gaze_color = (0, 0, 255)  # Red\n",
    "    else:\n",
    "        gaze_color = (0, 255, 0)  # Green (default)\n",
    "    overlay_text(frame, f\"Gaze: {gaze_direction}\", (10, 30), gaze_color)\n",
    "\n",
    "    # Blink detection and claw state\n",
    "    left_eye_landmarks = [face_landmarks.landmark[133], face_landmarks.landmark[159], face_landmarks.landmark[145], face_landmarks.landmark[33]]\n",
    "    right_eye_landmarks = [face_landmarks.landmark[362], face_landmarks.landmark[386], face_landmarks.landmark[374], face_landmarks.landmark[263]]\n",
    "    current_blink = is_blinking(left_eye_landmarks) or is_blinking(right_eye_landmarks)\n",
    "    if current_blink and not blink_detected:\n",
    "        blink_detected = True\n",
    "        claw_state = not claw_state\n",
    "        send_command_to_arduino(arduino, 'OPEN' if claw_state else 'CLOSE')\n",
    "    elif not current_blink:\n",
    "        blink_detected = False\n",
    "    claw_color = (0, 255, 0) if claw_state else (0, 0, 255)  # Green if open, Red if closed\n",
    "    overlay_text(frame, f\"Claw: {'Open' if claw_state else 'Closed'}\", (10, 60), claw_color)\n",
    "\n",
    "    # Eyebrow movement\n",
    "    eyebrow_state, baseline_position = calculate_eyebrow_movement(\n",
    "        [(lm.x, lm.y, lm.z) for lm in face_landmarks.landmark],\n",
    "        LEFT_BROW, RIGHT_BROW, baseline_position, movement_threshold\n",
    "    )\n",
    "    send_command_to_arduino(arduino, \"UP\" if eyebrow_state == \"Eyebrows Raised\" else \"DOWN\")\n",
    "    eyebrow_color = (0, 0, 255) if eyebrow_state == \"Eyebrows Raised\" else (0, 255, 0)  # Red if raised, Green if neutral\n",
    "    overlay_text(frame, f\"Eyebrows: {eyebrow_state}\", (10, 90), eyebrow_color)\n",
    "\n",
    "    # Mouth status\n",
    "    mouth_status = detect_mouth_status(face_landmarks)\n",
    "    send_command_to_arduino(arduino, 'EXTEND' if mouth_status == \"Mouth Open\" else 'RETRACT')\n",
    "    mouth_color = (0, 0, 255) if mouth_status == \"Mouth Open\" else (0, 255, 0)  # Red if open, Green if closed\n",
    "    overlay_text(frame, f\"Mouth: {mouth_status}\", (10, 120), mouth_color)\n",
    "\n",
    "    return baseline_position\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    global blink_detected, claw_state\n",
    "    blink_detected = False\n",
    "    claw_state = False\n",
    "    \n",
    "    # Initialize resources\n",
    "    arduino = initialize_serial('COM3')\n",
    "    face_mesh = initialize_face_mesh()\n",
    "    cap1 = cv2.VideoCapture(0)\n",
    "    cap2 = cv2.VideoCapture(1)\n",
    "    \n",
    "    baseline_position = None\n",
    "    movement_threshold = 0.01\n",
    "\n",
    "    while cap1.isOpened() and cap2.isOpened():\n",
    "        success1, frame1 = cap1.read()\n",
    "        success2, frame2 = cap2.read()\n",
    "        if not success1 or not success2:\n",
    "            print(\"Error reading frames.\")\n",
    "            break\n",
    "        \n",
    "        # Flip the frames horizontally for better visualization\n",
    "        frame1 = cv2.flip(frame1, 1)\n",
    "        frame2 = cv2.flip(frame2, 1)\n",
    "        \n",
    "        # Convert frames to RGB for processing\n",
    "        frame_rgb = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        results = face_mesh.process(frame_rgb)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                baseline_position = process_face_landmarks(face_landmarks, arduino, baseline_position, movement_threshold, frame1)\n",
    "\n",
    "        # Resize frames for better visualization\n",
    "        frame1_resized = cv2.resize(frame1, (640, 400))\n",
    "        frame2_resized = cv2.resize(frame2, (640, 400))\n",
    "\n",
    "        # Stack frames verticallyq\n",
    "        stacked_frame = np.vstack((frame1_resized, frame2_resized))\n",
    "\n",
    "        # Show the stacked frames with overlayed text\n",
    "        cv2.imshow(\"Feed\", stacked_frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap1.release()\n",
    "    cap2.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9fdc8e",
   "metadata": {},
   "source": [
    "### WITH EYE LANDMARKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ed4eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial connection established.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import serial\n",
    "import time\n",
    "\n",
    "# Initialize serial communication with Arduino\n",
    "def initialize_serial(port, baud_rate=9600):\n",
    "    try:\n",
    "        arduino = serial.Serial(port, baud_rate)\n",
    "        time.sleep(2)  # Allow time for connection to initialize\n",
    "        print(\"Serial connection established.\")\n",
    "        return arduino\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing serial: {e}\")\n",
    "        return None\n",
    "\n",
    "# Initialize Mediapipe FaceMesh\n",
    "def initialize_face_mesh():\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    return mp_face_mesh.FaceMesh(refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Function to calculate gaze direction\n",
    "def calculate_gaze_direction(iris_center, eye_corners):\n",
    "    left_corner = eye_corners[0]\n",
    "    right_corner = eye_corners[1]\n",
    "    horizontal_ratio = (iris_center.x - left_corner.x) / (right_corner.x - left_corner.x)\n",
    "    return horizontal_ratio\n",
    "\n",
    "# Function to detect blinking\n",
    "\n",
    "def is_blinking(eye_landmarks, threshold=0.2):\n",
    "    top = np.array([eye_landmarks[1].x, eye_landmarks[1].y])\n",
    "    bottom = np.array([eye_landmarks[2].x, eye_landmarks[2].y])\n",
    "    left = np.array([eye_landmarks[0].x, eye_landmarks[0].y])\n",
    "    right = np.array([eye_landmarks[3].x, eye_landmarks[3].y])\n",
    "\n",
    "    vertical_distance = np.linalg.norm(top - bottom)\n",
    "    horizontal_distance = np.linalg.norm(left - right)\n",
    "\n",
    "    blink_ratio = vertical_distance / horizontal_distance\n",
    "    return blink_ratio < threshold\n",
    "\n",
    "# Function to detect mouth status\n",
    "def detect_mouth_status(landmarks):\n",
    "    upper_lip_y = landmarks.landmark[61].y\n",
    "    lower_lip_y = landmarks.landmark[17].y\n",
    "    lip_distance = abs(upper_lip_y - lower_lip_y)\n",
    "    \n",
    "    left_eye = landmarks.landmark[33]\n",
    "    right_eye = landmarks.landmark[263]\n",
    "    eye_distance = abs(left_eye.x - right_eye.x)\n",
    "    \n",
    "    threshold = 0.025 + (eye_distance * 0.1)\n",
    "    return \"Mouth Open\" if lip_distance > threshold else \"Mouth Closed\"\n",
    "\n",
    "# Function to calculate eyebrow movement\n",
    "def calculate_eyebrow_movement(landmarks, left_brow_indices, right_brow_indices, baseline, movement_threshold):\n",
    "    left_brow_y = np.mean([landmarks[i][1] for i in left_brow_indices])\n",
    "    right_brow_y = np.mean([landmarks[i][1] for i in right_brow_indices])\n",
    "    avg_brow_y = (left_brow_y + right_brow_y) / 2\n",
    "\n",
    "    if baseline is None:\n",
    "        baseline = avg_brow_y\n",
    "        return \"Neutral\", baseline\n",
    "\n",
    "    if avg_brow_y < baseline - movement_threshold:\n",
    "        return \"Eyebrows Raised\", baseline\n",
    "    else:\n",
    "        baseline = 0.9 * baseline + 0.1 * avg_brow_y\n",
    "        return \"Neutral\", baseline\n",
    "\n",
    "# Function to send commands to Arduino\n",
    "def send_command_to_arduino(arduino, command):\n",
    "    if arduino:\n",
    "        try:\n",
    "            arduino.write(f\"{command}\\n\".encode())\n",
    "        except Exception as e:\n",
    "            print(f\"Error sending command: {e}\")\n",
    "\n",
    "# Function to overlay detection results\n",
    "def overlay_text(frame, text, position, color=(0, 255, 0)):\n",
    "    cv2.putText(frame, text, position, cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2, cv2.LINE_AA)\n",
    "\n",
    "# Function to process face landmarks\n",
    "def process_face_landmarks(face_landmarks, arduino, baseline_position, movement_threshold, frame):\n",
    "    global blink_detected, claw_state\n",
    "    \n",
    "    LEFT_BROW = [46, 53, 52, 65, 55, 63, 105, 66, 107]\n",
    "    RIGHT_BROW = [276, 283, 282, 295, 285, 293, 334, 296, 336]\n",
    "    \n",
    "    # Gaze detection\n",
    "    left_iris = face_landmarks.landmark[468]\n",
    "    right_iris = face_landmarks.landmark[473]\n",
    "    left_eye_corners = [face_landmarks.landmark[33], face_landmarks.landmark[133]]\n",
    "    right_eye_corners = [face_landmarks.landmark[362], face_landmarks.landmark[263]]\n",
    "    \n",
    "    avg_gaze_ratio = (calculate_gaze_direction(left_iris, left_eye_corners) +\n",
    "                      calculate_gaze_direction(right_iris, right_eye_corners)) / 2\n",
    "    gaze_direction = \"Center\"\n",
    "    if avg_gaze_ratio < 0.35:\n",
    "        send_command_to_arduino(arduino, 'L')\n",
    "        gaze_direction = \"Left\"\n",
    "        gaze_color = (0, 0, 255)  # Red\n",
    "    elif avg_gaze_ratio > 0.65:\n",
    "        send_command_to_arduino(arduino, 'R')\n",
    "        gaze_direction = \"Right\"\n",
    "        gaze_color = (0, 0, 255)  # Red\n",
    "    else:\n",
    "        gaze_color = (0, 255, 0)  # Green (default)\n",
    "    overlay_text(frame, f\"Gaze: {gaze_direction}\", (10, 30), gaze_color)\n",
    "\n",
    "    # Blink detection and claw state\n",
    "    left_eye_landmarks = [face_landmarks.landmark[133], face_landmarks.landmark[159], face_landmarks.landmark[145], face_landmarks.landmark[33]]\n",
    "    right_eye_landmarks = [face_landmarks.landmark[362], face_landmarks.landmark[386], face_landmarks.landmark[374], face_landmarks.landmark[263]]\n",
    "    current_blink = is_blinking(left_eye_landmarks) or is_blinking(right_eye_landmarks)\n",
    "    if current_blink and not blink_detected:\n",
    "        blink_detected = True\n",
    "        claw_state = not claw_state\n",
    "        send_command_to_arduino(arduino, 'OPEN' if claw_state else 'CLOSE')\n",
    "    elif not current_blink:\n",
    "        blink_detected = False\n",
    "    claw_color = (0, 255, 0) if claw_state else (0, 0, 255)  # Green if open, Red if closed\n",
    "    overlay_text(frame, f\"Claw: {'Open' if claw_state else 'Closed'}\", (10, 60), claw_color)\n",
    "\n",
    "    # Eyebrow movement\n",
    "    eyebrow_state, baseline_position = calculate_eyebrow_movement(\n",
    "        [(lm.x, lm.y, lm.z) for lm in face_landmarks.landmark],\n",
    "        LEFT_BROW, RIGHT_BROW, baseline_position, movement_threshold\n",
    "    )\n",
    "    send_command_to_arduino(arduino, \"UP\" if eyebrow_state == \"Eyebrows Raised\" else \"DOWN\")\n",
    "    eyebrow_color = (0, 0, 255) if eyebrow_state == \"Eyebrows Raised\" else (0, 255, 0)  # Red if raised, Green if neutral\n",
    "    overlay_text(frame, f\"Eyebrows: {eyebrow_state}\", (10, 90), eyebrow_color)\n",
    "\n",
    "    # Mouth status\n",
    "    mouth_status = detect_mouth_status(face_landmarks)\n",
    "    send_command_to_arduino(arduino, 'EXTEND' if mouth_status == \"Mouth Open\" else 'RETRACT')\n",
    "    mouth_color = (0, 0, 255) if mouth_status == \"Mouth Open\" else (0, 255, 0)  # Red if open, Green if closed\n",
    "    overlay_text(frame, f\"Mouth: {mouth_status}\", (10, 120), mouth_color)\n",
    "\n",
    "    # Draw the pupil landmarks in red for both eyes\n",
    "    left_pupil_landmark = face_landmarks.landmark[468]  # Left pupil center\n",
    "    right_pupil_landmark = face_landmarks.landmark[473]  # Right pupil center\n",
    "    height, width, _ = frame.shape\n",
    "    \n",
    "    left_pupil_x, left_pupil_y = int(left_pupil_landmark.x * width), int(left_pupil_landmark.y * height)\n",
    "    right_pupil_x, right_pupil_y = int(right_pupil_landmark.x * width), int(right_pupil_landmark.y * height)\n",
    "    \n",
    "    # Red dot for both pupils\n",
    "    cv2.circle(frame, (left_pupil_x, left_pupil_y), 3, (0, 0, 255), -1)\n",
    "    cv2.circle(frame, (right_pupil_x, right_pupil_y), 3, (0, 0, 255), -1)\n",
    "\n",
    "    return baseline_position\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    global blink_detected, claw_state\n",
    "    blink_detected = False\n",
    "    claw_state = False\n",
    "    \n",
    "    # Initialize resources\n",
    "    arduino = initialize_serial('COM4')\n",
    "    face_mesh = initialize_face_mesh()\n",
    "    cap1 = cv2.VideoCapture(0)\n",
    "    cap2 = cv2.VideoCapture(1)\n",
    "    \n",
    "    baseline_position = None\n",
    "    movement_threshold = 0.01\n",
    "\n",
    "    while cap1.isOpened() and cap2.isOpened():\n",
    "        success1, frame1 = cap1.read()\n",
    "        success2, frame2 = cap2.read()\n",
    "        if not success1 or not success2:\n",
    "            print(\"Error reading frames.\")\n",
    "            break\n",
    "        \n",
    "        # Flip the frames horizontally for better visualization\n",
    "        frame1 = cv2.flip(frame1, 1)\n",
    "        frame2 = cv2.flip(frame2, 1)\n",
    "        \n",
    "        # Convert frames to RGB for processing\n",
    "        frame_rgb = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        results = face_mesh.process(frame_rgb)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                baseline_position = process_face_landmarks(face_landmarks, arduino, baseline_position, movement_threshold, frame1)\n",
    "\n",
    "        # Resize frames for better visualization\n",
    "        frame1_resized = cv2.resize(frame1, (640, 400))\n",
    "        frame2_resized = cv2.resize(frame2, (640, 400))\n",
    "\n",
    "        # Stack frames vertically\n",
    "        stacked_frame = np.vstack((frame1_resized, frame2_resized))\n",
    "\n",
    "        # Show the stacked frames with overlayed text\n",
    "        cv2.imshow(\"Feed\", stacked_frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap1.release()\n",
    "    cap2.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa603ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
