{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e20b728",
   "metadata": {},
   "source": [
    "### IRIS AND BLINKING DETECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3db341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Webcam capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Function to calculate the gaze ratio\n",
    "def calculate_gaze_direction(iris_center, eye_corners):\n",
    "    left_corner = eye_corners[0]\n",
    "    right_corner = eye_corners[1]\n",
    "\n",
    "    # Horizontal gaze ratio\n",
    "    horizontal_ratio = (iris_center.x - left_corner.x) / (right_corner.x - left_corner.x)\n",
    "    return horizontal_ratio\n",
    "\n",
    "# Function to calculate blinking\n",
    "def is_blinking(eye_landmarks, threshold=0.2):\n",
    "    # Get vertical and horizontal landmarks for the eye\n",
    "    top = np.array([eye_landmarks[1].x, eye_landmarks[1].y])\n",
    "    bottom = np.array([eye_landmarks[2].x, eye_landmarks[2].y])\n",
    "    left = np.array([eye_landmarks[0].x, eye_landmarks[0].y])\n",
    "    right = np.array([eye_landmarks[3].x, eye_landmarks[3].y])\n",
    "\n",
    "    # Calculate vertical and horizontal distances\n",
    "    vertical_distance = np.linalg.norm(top - bottom)\n",
    "    horizontal_distance = np.linalg.norm(left - right)\n",
    "\n",
    "    # Blinking ratio\n",
    "    blink_ratio = vertical_distance / horizontal_distance\n",
    "\n",
    "    # Return True if blinking, False otherwise\n",
    "    return blink_ratio < threshold\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "\n",
    "    # Flip the frame horizontally for a mirror view\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame using Face Mesh\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "\n",
    "    gaze_direction = \"Unknown\"\n",
    "    blinking = False\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Get left and right iris centers and eye corners\n",
    "            left_iris = face_landmarks.landmark[468]\n",
    "            right_iris = face_landmarks.landmark[473]\n",
    "\n",
    "            left_eye_corners = [face_landmarks.landmark[33], face_landmarks.landmark[133]]  # Left eye corners\n",
    "            right_eye_corners = [face_landmarks.landmark[362], face_landmarks.landmark[263]]  # Right eye corners\n",
    "\n",
    "            # Calculate gaze ratios for both eyes\n",
    "            left_gaze_ratio = calculate_gaze_direction(left_iris, left_eye_corners)\n",
    "            right_gaze_ratio = calculate_gaze_direction(right_iris, right_eye_corners)\n",
    "            \n",
    "            # Average gaze ratio\n",
    "            avg_gaze_ratio = (left_gaze_ratio + right_gaze_ratio) / 2\n",
    "\n",
    "            # Determine gaze direction\n",
    "            if avg_gaze_ratio < 0.35:  # Adjust thresholds if needed\n",
    "                gaze_direction = \"Left\"\n",
    "            elif avg_gaze_ratio > 0.65:\n",
    "                gaze_direction = \"Right\"\n",
    "            else:\n",
    "                gaze_direction = \"Center\"\n",
    "\n",
    "            # Detect blinking for both eyes\n",
    "            left_eye_landmarks = [\n",
    "                face_landmarks.landmark[133],  # Left corner\n",
    "                face_landmarks.landmark[159],  # Top\n",
    "                face_landmarks.landmark[145],  # Bottom\n",
    "                face_landmarks.landmark[33],  # Right corner\n",
    "            ]\n",
    "            right_eye_landmarks = [\n",
    "                face_landmarks.landmark[362],  # Left corner\n",
    "                face_landmarks.landmark[386],  # Top\n",
    "                face_landmarks.landmark[374],  # Bottom\n",
    "                face_landmarks.landmark[263],  # Right corner\n",
    "            ]\n",
    "            left_blinking = is_blinking(left_eye_landmarks)\n",
    "            right_blinking = is_blinking(right_eye_landmarks)\n",
    "            blinking = left_blinking or right_blinking\n",
    "\n",
    "            # Visualize iris landmarks\n",
    "            for landmark in [left_iris, right_iris]:\n",
    "                x = int(landmark.x * frame.shape[1])\n",
    "                y = int(landmark.y * frame.shape[0])\n",
    "                cv2.circle(frame, (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "    # Display the gaze direction\n",
    "    cv2.putText(frame, f\"Gaze: {gaze_direction}\", (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Display blinking status\n",
    "    blink_text = \"Blinking\" if blinking else \"Not Blinking\"\n",
    "    cv2.putText(frame, f\"{blink_text}\", (30, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    # Show the output frame\n",
    "    cv2.imshow(\"MediaPipe Iris Tracking\", frame)\n",
    "\n",
    "    # Exit the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d970ba5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb804a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4825bfbf",
   "metadata": {},
   "source": [
    "### IRIS DETECTOR WITH UP AND DOWN EYE MOVEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d08b683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Webcam capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Function to calculate the horizontal gaze ratio\n",
    "def calculate_gaze_direction(iris_center, eye_corners):\n",
    "    left_corner = eye_corners[0]\n",
    "    right_corner = eye_corners[1]\n",
    "    \n",
    "    # Horizontal gaze ratio\n",
    "    horizontal_ratio = (iris_center.x - left_corner.x) / (right_corner.x - left_corner.x)\n",
    "    return horizontal_ratio\n",
    "\n",
    "# Function to calculate the vertical gaze ratio\n",
    "def calculate_vertical_gaze_direction(iris_center, eye_corners):\n",
    "    top_corner = eye_corners[1]\n",
    "    bottom_corner = eye_corners[2]\n",
    "    \n",
    "    # Vertical gaze ratio\n",
    "    vertical_ratio = (iris_center.y - top_corner.y) / (bottom_corner.y - top_corner.y)\n",
    "    return vertical_ratio\n",
    "\n",
    "# Function to calculate blinking\n",
    "def is_blinking(eye_landmarks, threshold=0.2):\n",
    "    # Get vertical and horizontal landmarks for the eye\n",
    "    top = np.array([eye_landmarks[1].x, eye_landmarks[1].y])\n",
    "    bottom = np.array([eye_landmarks[2].x, eye_landmarks[2].y])\n",
    "    left = np.array([eye_landmarks[0].x, eye_landmarks[0].y])\n",
    "    right = np.array([eye_landmarks[3].x, eye_landmarks[3].y])\n",
    "\n",
    "    # Calculate vertical and horizontal distances\n",
    "    vertical_distance = np.linalg.norm(top - bottom)\n",
    "    horizontal_distance = np.linalg.norm(left - right)\n",
    "\n",
    "    # Blinking ratio\n",
    "    blink_ratio = vertical_distance / horizontal_distance\n",
    "\n",
    "    # Return True if blinking, False otherwise\n",
    "    return blink_ratio < threshold\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "\n",
    "    # Flip the frame horizontally for a mirror view\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame using Face Mesh\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "\n",
    "    gaze_direction = \"Unknown\"\n",
    "    vertical_gaze_direction = \"Unknown\"\n",
    "    blinking = False\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Get left and right iris centers and eye corners\n",
    "            left_iris = face_landmarks.landmark[468]\n",
    "            right_iris = face_landmarks.landmark[473]\n",
    "\n",
    "            left_eye_corners = [face_landmarks.landmark[33], face_landmarks.landmark[133], face_landmarks.landmark[145]]  # Left eye corners\n",
    "            right_eye_corners = [face_landmarks.landmark[362], face_landmarks.landmark[386], face_landmarks.landmark[374]]  # Right eye corners\n",
    "\n",
    "            # Calculate gaze ratios for both eyes (horizontal)\n",
    "            left_gaze_ratio = calculate_gaze_direction(left_iris, left_eye_corners)\n",
    "            right_gaze_ratio = calculate_gaze_direction(right_iris, right_eye_corners)\n",
    "\n",
    "            # Average horizontal gaze ratio\n",
    "            avg_gaze_ratio = (left_gaze_ratio + right_gaze_ratio) / 2\n",
    "\n",
    "            # Determine horizontal gaze direction (Left, Center, Right)\n",
    "            if avg_gaze_ratio < 0.35:\n",
    "                gaze_direction = \"Left\"\n",
    "            elif avg_gaze_ratio > 0.65:\n",
    "                gaze_direction = \"Right\"\n",
    "            else:\n",
    "                gaze_direction = \"Center\"\n",
    "\n",
    "            # Calculate vertical gaze ratio for both eyes (up/down)\n",
    "            left_vertical_gaze_ratio = calculate_vertical_gaze_direction(left_iris, left_eye_corners)\n",
    "            right_vertical_gaze_ratio = calculate_vertical_gaze_direction(right_iris, right_eye_corners)\n",
    "\n",
    "            # Average vertical gaze ratio\n",
    "            avg_vertical_gaze_ratio = (left_vertical_gaze_ratio + right_vertical_gaze_ratio) / 2\n",
    "\n",
    "            # Determine vertical gaze direction (Up, Center, Down)\n",
    "            if avg_vertical_gaze_ratio < 0.35:\n",
    "                vertical_gaze_direction = \"Up\"\n",
    "            elif avg_vertical_gaze_ratio > 0.65:\n",
    "                vertical_gaze_direction = \"Down\"\n",
    "            else:\n",
    "                vertical_gaze_direction = \"Center\"\n",
    "\n",
    "            # Detect blinking for both eyes\n",
    "            left_eye_landmarks = [\n",
    "                face_landmarks.landmark[133],  # Left corner\n",
    "                face_landmarks.landmark[159],  # Top\n",
    "                face_landmarks.landmark[145],  # Bottom\n",
    "                face_landmarks.landmark[33],   # Right corner\n",
    "            ]\n",
    "            right_eye_landmarks = [\n",
    "                face_landmarks.landmark[362],  # Left corner\n",
    "                face_landmarks.landmark[386],  # Top\n",
    "                face_landmarks.landmark[374],  # Bottom\n",
    "                face_landmarks.landmark[263],  # Right corner\n",
    "            ]\n",
    "            left_blinking = is_blinking(left_eye_landmarks)\n",
    "            right_blinking = is_blinking(right_eye_landmarks)\n",
    "            blinking = left_blinking or right_blinking\n",
    "\n",
    "            # Visualize iris landmarks\n",
    "            for landmark in [left_iris, right_iris]:\n",
    "                x = int(landmark.x * frame.shape[1])\n",
    "                y = int(landmark.y * frame.shape[0])\n",
    "                cv2.circle(frame, (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "    # Display the gaze direction\n",
    "    cv2.putText(frame, f\"Gaze Horizontal: {gaze_direction}\", (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the vertical gaze direction\n",
    "    cv2.putText(frame, f\"Gaze Vertical: {vertical_gaze_direction}\", (30, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    # Display blinking status\n",
    "    blink_text = \"Blinking\" if blinking else \"Not Blinking\"\n",
    "    cv2.putText(frame, f\"{blink_text}\", (30, 130), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    # Show the output frame\n",
    "    cv2.imshow(\"MediaPipe Iris Tracking\", frame)\n",
    "\n",
    "    # Exit the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fb2daf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b57111d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b64efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b7b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1776e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c337263",
   "metadata": {},
   "source": [
    "### ONLY THE BASE IS WORKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2a8e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import serial\n",
    "import time\n",
    "\n",
    "# Initialize serial communication with Arduino\n",
    "arduino = serial.Serial(port='COM3', baudrate=9600, timeout=.1)  # Replace 'COM3' with the appropriate port for your Arduino\n",
    "time.sleep(2)  # Give the connection a moment to initialize\n",
    "\n",
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Webcam capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Function to calculate the gaze ratio\n",
    "def calculate_gaze_direction(iris_center, eye_corners):\n",
    "    left_corner = eye_corners[0]\n",
    "    right_corner = eye_corners[1]\n",
    "\n",
    "    # Horizontal gaze ratio\n",
    "    horizontal_ratio = (iris_center.x - left_corner.x) / (right_corner.x - left_corner.x)\n",
    "    return horizontal_ratio\n",
    "\n",
    "# Function to calculate blinking\n",
    "def is_blinking(eye_landmarks, threshold=0.2):\n",
    "    # Get vertical and horizontal landmarks for the eye\n",
    "    top = np.array([eye_landmarks[1].x, eye_landmarks[1].y])\n",
    "    bottom = np.array([eye_landmarks[2].x, eye_landmarks[2].y])\n",
    "    left = np.array([eye_landmarks[0].x, eye_landmarks[0].y])\n",
    "    right = np.array([eye_landmarks[3].x, eye_landmarks[3].y])\n",
    "\n",
    "    # Calculate vertical and horizontal distances\n",
    "    vertical_distance = np.linalg.norm(top - bottom)\n",
    "    horizontal_distance = np.linalg.norm(left - right)\n",
    "\n",
    "    # Blinking ratio\n",
    "    blink_ratio = vertical_distance / horizontal_distance\n",
    "\n",
    "    # Return True if blinking, False otherwise\n",
    "    return blink_ratio < threshold\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "\n",
    "    # Flip the frame horizontally for a mirror view\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame using Face Mesh\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "\n",
    "    gaze_direction = \"Unknown\"\n",
    "    blinking = False\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Get left and right iris centers and eye corners\n",
    "            left_iris = face_landmarks.landmark[468]\n",
    "            right_iris = face_landmarks.landmark[473]\n",
    "\n",
    "            left_eye_corners = [face_landmarks.landmark[33], face_landmarks.landmark[133]]  # Left eye corners\n",
    "            right_eye_corners = [face_landmarks.landmark[362], face_landmarks.landmark[263]]  # Right eye corners\n",
    "\n",
    "            # Calculate gaze ratios for both eyes\n",
    "            left_gaze_ratio = calculate_gaze_direction(left_iris, left_eye_corners)\n",
    "            right_gaze_ratio = calculate_gaze_direction(right_iris, right_eye_corners)\n",
    "\n",
    "            # Average gaze ratio\n",
    "            avg_gaze_ratio = (left_gaze_ratio + right_gaze_ratio) / 2\n",
    "\n",
    "            # Determine gaze direction\n",
    "            if avg_gaze_ratio < 0.35:  # Adjust thresholds if needed\n",
    "                gaze_direction = \"Left\"\n",
    "                arduino.write(b'L\\n')  # Send 'L' to Arduino for Left\n",
    "            elif avg_gaze_ratio > 0.65:\n",
    "                gaze_direction = \"Right\"\n",
    "                arduino.write(b'R\\n')  # Send 'R' to Arduino for Right\n",
    "            else:\n",
    "                gaze_direction = \"Center\"\n",
    "\n",
    "            # Detect blinking for both eyes\n",
    "            left_eye_landmarks = [\n",
    "                face_landmarks.landmark[133],  # Left corner\n",
    "                face_landmarks.landmark[159],  # Top\n",
    "                face_landmarks.landmark[145],  # Bottom\n",
    "                face_landmarks.landmark[33],  # Right corner\n",
    "            ]\n",
    "            right_eye_landmarks = [\n",
    "                face_landmarks.landmark[362],  # Left corner\n",
    "                face_landmarks.landmark[386],  # Top\n",
    "                face_landmarks.landmark[374],  # Bottom\n",
    "                face_landmarks.landmark[263],  # Right corner\n",
    "            ]\n",
    "            left_blinking = is_blinking(left_eye_landmarks)\n",
    "            right_blinking = is_blinking(right_eye_landmarks)\n",
    "            blinking = left_blinking or right_blinking\n",
    "\n",
    "            if blinking:\n",
    "                arduino.write(b'B\\n')  # Send 'B' to Arduino for Blink\n",
    "\n",
    "            # Visualize iris landmarks\n",
    "            for landmark in [left_iris, right_iris]:\n",
    "                x = int(landmark.x * frame.shape[1])\n",
    "                y = int(landmark.y * frame.shape[0])\n",
    "                cv2.circle(frame, (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "    # Display the gaze direction\n",
    "    cv2.putText(frame, f\"Gaze: {gaze_direction}\", (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Display blinking status\n",
    "    blink_text = \"Blinking\" if blinking else \"Not Blinking\"\n",
    "    cv2.putText(frame, f\"{blink_text}\", (30, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    # Show the output frame\n",
    "    cv2.imshow(\"MediaPipe Iris Tracking\", frame)\n",
    "\n",
    "    # Exit the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c93df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac21112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fc12ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6740a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d041a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405cb6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2ba734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ac803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c3b310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ce2287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132b8aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b6568a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f08c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd45ea70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c605145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d766dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19509ec7",
   "metadata": {},
   "source": [
    "### WORKING CLAW ONLY CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f060574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import serial\n",
    "import time\n",
    "\n",
    "# Initialize serial communication with Arduino\n",
    "arduino = serial.Serial(port='COM3', baudrate=9600, timeout=.1)  # Adjust the port as needed\n",
    "time.sleep(2)  # Allow time for the connection to initialize\n",
    "\n",
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Webcam capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "claw_state = False  # False: Closed, True: Open\n",
    "blink_detected = False  # Tracks if blink was detected in the previous frame\n",
    "\n",
    "# Function to calculate the gaze direction\n",
    "def calculate_gaze_direction(iris_center, eye_corners):\n",
    "    left_corner = eye_corners[0]\n",
    "    right_corner = eye_corners[1]\n",
    "\n",
    "    # Horizontal gaze ratio\n",
    "    horizontal_ratio = (iris_center.x - left_corner.x) / (right_corner.x - left_corner.x)\n",
    "    return horizontal_ratio\n",
    "\n",
    "# Function to calculate blinking\n",
    "def is_blinking(eye_landmarks, threshold=0.2):\n",
    "    top = np.array([eye_landmarks[1].x, eye_landmarks[1].y])\n",
    "    bottom = np.array([eye_landmarks[2].x, eye_landmarks[2].y])\n",
    "    left = np.array([eye_landmarks[0].x, eye_landmarks[0].y])\n",
    "    right = np.array([eye_landmarks[3].x, eye_landmarks[3].y])\n",
    "\n",
    "    vertical_distance = np.linalg.norm(top - bottom)\n",
    "    horizontal_distance = np.linalg.norm(left - right)\n",
    "\n",
    "    blink_ratio = vertical_distance / horizontal_distance\n",
    "    return blink_ratio < threshold\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "\n",
    "    gaze_direction = \"Unknown\"\n",
    "    current_blink = False\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            left_iris = face_landmarks.landmark[468]\n",
    "            right_iris = face_landmarks.landmark[473]\n",
    "\n",
    "            left_eye_corners = [face_landmarks.landmark[33], face_landmarks.landmark[133]]\n",
    "            right_eye_corners = [face_landmarks.landmark[362], face_landmarks.landmark[263]]\n",
    "\n",
    "            left_gaze_ratio = calculate_gaze_direction(left_iris, left_eye_corners)\n",
    "            right_gaze_ratio = calculate_gaze_direction(right_iris, right_eye_corners)\n",
    "            avg_gaze_ratio = (left_gaze_ratio + right_gaze_ratio) / 2\n",
    "\n",
    "            if avg_gaze_ratio < 0.35:\n",
    "                gaze_direction = \"Left\"\n",
    "                arduino.write(b'L\\n')  # Send 'L' to Arduino for left movement\n",
    "            elif avg_gaze_ratio > 0.65:\n",
    "                gaze_direction = \"Right\"\n",
    "                arduino.write(b'R\\n')  # Send 'R' to Arduino for right movement\n",
    "            else:\n",
    "                gaze_direction = \"Center\"\n",
    "                arduino.write(b'C\\n')  # Send 'C' to Arduino for center position\n",
    "\n",
    "            left_eye_landmarks = [\n",
    "                face_landmarks.landmark[133],  # Left corner\n",
    "                face_landmarks.landmark[159],  # Top\n",
    "                face_landmarks.landmark[145],  # Bottom\n",
    "                face_landmarks.landmark[33],  # Right corner\n",
    "            ]\n",
    "            right_eye_landmarks = [\n",
    "                face_landmarks.landmark[362],  # Left corner\n",
    "                face_landmarks.landmark[386],  # Top\n",
    "                face_landmarks.landmark[374],  # Bottom\n",
    "                face_landmarks.landmark[263],  # Right corner\n",
    "            ]\n",
    "            left_blinking = is_blinking(left_eye_landmarks)\n",
    "            right_blinking = is_blinking(right_eye_landmarks)\n",
    "            current_blink = left_blinking or right_blinking\n",
    "\n",
    "            # Handle blink state\n",
    "            if current_blink and not blink_detected:\n",
    "                blink_detected = True\n",
    "                claw_state = not claw_state  # Toggle claw state\n",
    "                # Send the servo position to Arduino based on claw state\n",
    "                if claw_state:\n",
    "                    arduino.write(b'OPEN\\n')  # Open claw (110 degrees)\n",
    "                else:\n",
    "                    arduino.write(b'CLOSE\\n')  # Close claw (90 degrees)\n",
    "            elif not current_blink:\n",
    "                blink_detected = False\n",
    "\n",
    "            # Draw red dots for iris\n",
    "            for landmark in [left_iris, right_iris]:\n",
    "                x = int(landmark.x * frame.shape[1])\n",
    "                y = int(landmark.y * frame.shape[0])\n",
    "                cv2.circle(frame, (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "    cv2.putText(frame, f\"Gaze: {gaze_direction}\", (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Claw State: {'Open' if claw_state else 'Closed'}\", (30, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"MediaPipe Iris Tracking\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d1af4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c64a1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9ca1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72512659",
   "metadata": {},
   "source": [
    "### WORKING CLAW AND BASE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeac33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import serial\n",
    "import time\n",
    "\n",
    "# Initialize serial communication with Arduino\n",
    "arduino = serial.Serial(port='COM3', baudrate=9600, timeout=.1)  # Adjust the port as needed\n",
    "time.sleep(2)  # Allow time for the connection to initialize\n",
    "\n",
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Webcam capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "claw_state = False  # False: Closed, True: Open\n",
    "blink_detected = False  # Tracks if blink was detected in the previous frame\n",
    "\n",
    "# Function to calculate the gaze direction\n",
    "def calculate_gaze_direction(iris_center, eye_corners):\n",
    "    left_corner = eye_corners[0]\n",
    "    right_corner = eye_corners[1]\n",
    "\n",
    "    # Horizontal gaze ratio\n",
    "    horizontal_ratio = (iris_center.x - left_corner.x) / (right_corner.x - left_corner.x)\n",
    "    return horizontal_ratio\n",
    "\n",
    "# Function to calculate blinking\n",
    "def is_blinking(eye_landmarks, threshold=0.2):\n",
    "    top = np.array([eye_landmarks[1].x, eye_landmarks[1].y])\n",
    "    bottom = np.array([eye_landmarks[2].x, eye_landmarks[2].y])\n",
    "    left = np.array([eye_landmarks[0].x, eye_landmarks[0].y])\n",
    "    right = np.array([eye_landmarks[3].x, eye_landmarks[3].y])\n",
    "\n",
    "    vertical_distance = np.linalg.norm(top - bottom)\n",
    "    horizontal_distance = np.linalg.norm(left - right)\n",
    "\n",
    "    blink_ratio = vertical_distance / horizontal_distance\n",
    "    return blink_ratio < threshold\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "\n",
    "    gaze_direction = \"Unknown\"\n",
    "    current_blink = False\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            left_iris = face_landmarks.landmark[468]\n",
    "            right_iris = face_landmarks.landmark[473]\n",
    "\n",
    "            left_eye_corners = [face_landmarks.landmark[33], face_landmarks.landmark[133]]\n",
    "            right_eye_corners = [face_landmarks.landmark[362], face_landmarks.landmark[263]]\n",
    "\n",
    "            left_gaze_ratio = calculate_gaze_direction(left_iris, left_eye_corners)\n",
    "            right_gaze_ratio = calculate_gaze_direction(right_iris, right_eye_corners)\n",
    "            avg_gaze_ratio = (left_gaze_ratio + right_gaze_ratio) / 2\n",
    "\n",
    "            # Adjust thresholds for gaze direction\n",
    "            if avg_gaze_ratio < 0.35:\n",
    "                gaze_direction = \"LEFT\"\n",
    "                arduino.write(b'L\\n')  # Send 'L' to Arduino for left movement\n",
    "            elif avg_gaze_ratio > 0.65:\n",
    "                gaze_direction = \"RIGHT\"\n",
    "                arduino.write(b'R\\n')  # Send 'R' to Arduino for right movement\n",
    "            else:\n",
    "                gaze_direction = \"CENTER\"\n",
    "                arduino.write(b'C\\n')  # Send 'C' to Arduino for center position\n",
    "\n",
    "            left_eye_landmarks = [\n",
    "                face_landmarks.landmark[133],  # Left corner\n",
    "                face_landmarks.landmark[159],  # Top\n",
    "                face_landmarks.landmark[145],  # Bottom\n",
    "                face_landmarks.landmark[33],  # Right corner\n",
    "            ]\n",
    "            right_eye_landmarks = [\n",
    "                face_landmarks.landmark[362],  # Left corner\n",
    "                face_landmarks.landmark[386],  # Top\n",
    "                face_landmarks.landmark[374],  # Bottom\n",
    "                face_landmarks.landmark[263],  # Right corner\n",
    "            ]\n",
    "            left_blinking = is_blinking(left_eye_landmarks)\n",
    "            right_blinking = is_blinking(right_eye_landmarks)\n",
    "            current_blink = left_blinking or right_blinking\n",
    "\n",
    "            # Handle blink state\n",
    "            if current_blink and not blink_detected:\n",
    "                blink_detected = True\n",
    "                claw_state = not claw_state  # Toggle claw state\n",
    "                # Send the servo position to Arduino based on claw state\n",
    "                if claw_state:\n",
    "                    arduino.write(b'OPEN\\n')  # Open claw (110 degrees)\n",
    "                else:\n",
    "                    arduino.write(b'CLOSE\\n')  # Close claw (90 degrees)\n",
    "            elif not current_blink:\n",
    "                blink_detected = False\n",
    "\n",
    "            # Draw red dots for iris\n",
    "            for landmark in [left_iris, right_iris]:\n",
    "                x = int(landmark.x * frame.shape[1])\n",
    "                y = int(landmark.y * frame.shape[0])\n",
    "                cv2.circle(frame, (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "    # Display gaze direction on the frame\n",
    "    cv2.putText(frame, f\"Gaze: {gaze_direction}\", (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Claw State: {'Open' if claw_state else 'Closed'}\", (30, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    # Show the output frame\n",
    "    cv2.imshow(\"MediaPipe Iris Tracking\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca69d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156bb3af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af936d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4499f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f2c614a",
   "metadata": {},
   "source": [
    "### EYEBROW MOVEMENT DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fdc8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Set up webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define a function to calculate the eyebrow movement (detect upward movement only)\n",
    "def calculate_eyebrow_movement(landmarks, left_brow_indices, right_brow_indices, baseline, movement_threshold):\n",
    "    # Get the vertical position (y-coordinate) of the eyebrows\n",
    "    left_brow_y = np.mean([landmarks[i][1] for i in left_brow_indices])\n",
    "    right_brow_y = np.mean([landmarks[i][1] for i in right_brow_indices])\n",
    "\n",
    "    # Calculate the average vertical position of both eyebrows\n",
    "    avg_brow_y = (left_brow_y + right_brow_y) / 2\n",
    "\n",
    "    # If no baseline, initialize it with the current position\n",
    "    if baseline is None:\n",
    "        baseline = avg_brow_y\n",
    "        return \"Neutral\", baseline\n",
    "\n",
    "    # Detect upward movement by comparing with the baseline\n",
    "    if avg_brow_y < baseline - movement_threshold:\n",
    "        return \"Up\", baseline\n",
    "    else:\n",
    "        # Update baseline slightly to adapt to natural movements\n",
    "        baseline = 0.9 * baseline + 0.1 * avg_brow_y\n",
    "        return \"Neutral\", baseline\n",
    "\n",
    "\n",
    "# Correct indices for the left and right eyebrows (provided by you)\n",
    "LEFT_BROW = [46, 53, 52, 65, 55, 63, 105, 66, 107]  # Left eyebrow indices\n",
    "RIGHT_BROW = [276, 283, 282, 295, 285, 293, 334, 296, 336]  # Right eyebrow indices\n",
    "\n",
    "# Initialize baseline and movement threshold\n",
    "baseline_position = None\n",
    "movement_threshold = 0.01  # Adjust this value to control sensitivity\n",
    "\n",
    "# Initialize the Face Mesh model\n",
    "with mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the frame to RGB for MediaPipe\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the frame to get face landmarks\n",
    "        results = face_mesh.process(frame_rgb)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                # Extract landmarks as a list of (x, y, z) tuples\n",
    "                landmarks = [(lm.x, lm.y, lm.z) for lm in face_landmarks.landmark]\n",
    "\n",
    "                # Check eyebrow movement\n",
    "                eyebrow_state, baseline_position = calculate_eyebrow_movement(\n",
    "                    landmarks, LEFT_BROW, RIGHT_BROW, baseline_position, movement_threshold\n",
    "                )\n",
    "\n",
    "                # Display the eyebrow state on the frame\n",
    "                cv2.putText(frame, f\"Eyebrow Movement: {eyebrow_state}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "                # Draw only the eyebrow landmarks (left and right)\n",
    "                for i in LEFT_BROW:\n",
    "                    x, y, _ = landmarks[i]\n",
    "                    cv2.circle(frame, (int(x * frame.shape[1]), int(y * frame.shape[0])), 2, (0, 255, 0), -1)\n",
    "                for i in RIGHT_BROW:\n",
    "                    x, y, _ = landmarks[i]\n",
    "                    cv2.circle(frame, (int(x * frame.shape[1]), int(y * frame.shape[0])), 2, (0, 255, 0), -1)\n",
    "\n",
    "        # Display the frame with the eyebrow landmarks and movement status\n",
    "        cv2.imshow(\"Eyebrow Movement Detection\", frame)\n",
    "\n",
    "        # Exit the loop when the 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release the webcam and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d5511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90498867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b50263aa",
   "metadata": {},
   "source": [
    "### EYEBROW WITH ARDUINO ELBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b8262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import serial  # For Arduino communication\n",
    "import time  # To allow time for serial communication setup\n",
    "\n",
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Arduino Serial Port Configuration\n",
    "arduino = serial.Serial(port=\"COM3\", baudrate=9600, timeout=1)  # Update COM3 to your port\n",
    "time.sleep(2)  # Wait for Arduino to initialize\n",
    "\n",
    "# Define a function to calculate the eyebrow movement (detect upward movement only)\n",
    "def calculate_eyebrow_movement(landmarks, left_brow_indices, right_brow_indices, baseline, movement_threshold):\n",
    "    left_brow_y = np.mean([landmarks[i][1] for i in left_brow_indices])\n",
    "    right_brow_y = np.mean([landmarks[i][1] for i in right_brow_indices])\n",
    "    avg_brow_y = (left_brow_y + right_brow_y) / 2\n",
    "\n",
    "    if baseline is None:\n",
    "        baseline = avg_brow_y\n",
    "        return \"Neutral\", baseline\n",
    "\n",
    "    if avg_brow_y < baseline - movement_threshold:\n",
    "        return \"Up\", baseline\n",
    "    else:\n",
    "        baseline = 0.9 * baseline + 0.1 * avg_brow_y\n",
    "        return \"Neutral\", baseline\n",
    "\n",
    "\n",
    "# Eyebrow landmark indices\n",
    "LEFT_BROW = [46, 53, 52, 65, 55, 63, 105, 66, 107]\n",
    "RIGHT_BROW = [276, 283, 282, 295, 285, 293, 334, 296, 336]\n",
    "\n",
    "# Initialize baseline and movement threshold\n",
    "baseline_position = None\n",
    "movement_threshold = 0.01\n",
    "\n",
    "# Initialize Face Mesh\n",
    "with mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(frame_rgb)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                landmarks = [(lm.x, lm.y, lm.z) for lm in face_landmarks.landmark]\n",
    "\n",
    "                # Detect eyebrow movement\n",
    "                eyebrow_state, baseline_position = calculate_eyebrow_movement(\n",
    "                    landmarks, LEFT_BROW, RIGHT_BROW, baseline_position, movement_threshold\n",
    "                )\n",
    "\n",
    "                # Send commands to Arduino based on the eyebrow state\n",
    "                if eyebrow_state == \"Up\":\n",
    "                    arduino.write(b\"UP\\n\")  # Send \"UP\" command\n",
    "                elif eyebrow_state == \"Neutral\":\n",
    "                    arduino.write(b\"DOWN\\n\")  # Send \"DOWN\" command\n",
    "\n",
    "                # Display the eyebrow state on the frame\n",
    "                cv2.putText(frame, f\"Eyebrow Movement: {eyebrow_state}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "                # Draw the eyebrow landmarks\n",
    "                for i in LEFT_BROW:\n",
    "                    x, y, _ = landmarks[i]\n",
    "                    cv2.circle(frame, (int(x * frame.shape[1]), int(y * frame.shape[0])), 2, (0, 255, 0), -1)\n",
    "                for i in RIGHT_BROW:\n",
    "                    x, y, _ = landmarks[i]\n",
    "                    cv2.circle(frame, (int(x * frame.shape[1]), int(y * frame.shape[0])), 2, (0, 255, 0), -1)\n",
    "\n",
    "        cv2.imshow(\"Eyebrow Movement Detection\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "arduino.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65140285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fab8044e",
   "metadata": {},
   "source": [
    "### MOUTH OPEN OR CLOSED DETECTION PYTHON ONLY CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0568b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize mediapipe face mesh and drawing utilities\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Start webcam feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize the face mesh model\n",
    "with mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Convert the frame to RGB (MediaPipe needs RGB images)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(rgb_frame)\n",
    "        \n",
    "        # Clear the frame to remove face mesh landmarks\n",
    "        annotated_frame = frame.copy()\n",
    "\n",
    "        # Process detected faces\n",
    "        if results.multi_face_landmarks:\n",
    "            for landmarks in results.multi_face_landmarks:\n",
    "                # Get the upper and lower lip landmarks\n",
    "                upper_lip_y = landmarks.landmark[61].y\n",
    "                lower_lip_y = landmarks.landmark[17].y\n",
    "\n",
    "                # Calculate the distance between the upper and lower lips (y-coordinate difference)\n",
    "                lip_distance = abs(upper_lip_y - lower_lip_y)\n",
    "\n",
    "                # Get landmarks for a reference distance to calculate dynamic threshold (between eyes or nose)\n",
    "                left_eye = landmarks.landmark[33]\n",
    "                right_eye = landmarks.landmark[263]\n",
    "                # Calculate the width between eyes as a reference\n",
    "                eye_distance = abs(left_eye.x - right_eye.x)\n",
    "\n",
    "                # Dynamic threshold based on face distance (based on eye width)\n",
    "                # The closer you are, the more sensitive the mouth open detection will be\n",
    "                # The farther you are, the less sensitive it becomes\n",
    "                threshold = 0.025 + (eye_distance * 0.1)  # Dynamic adjustment for threshold\n",
    "\n",
    "                # Detect if the mouth is open or closed\n",
    "                if lip_distance > threshold:  # Dynamic threshold for mouth open detection\n",
    "                    mouth_status = \"Mouth Open\"\n",
    "                else:\n",
    "                    mouth_status = \"Mouth Closed\"\n",
    "\n",
    "                # Display the mouth status on the frame\n",
    "                cv2.putText(annotated_frame, mouth_status, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Display the annotated frame without face mesh\n",
    "        cv2.imshow(\"Mouth Open/Closed Detection\", annotated_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the webcam feed and close the window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9936576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89b433a3",
   "metadata": {},
   "source": [
    "### MOUTH OPEN WITH ARDUINO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4dc301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import serial\n",
    "import time\n",
    "\n",
    "# Initialize serial communication (adjust 'COM3' and 9600 as needed for your setup)\n",
    "arduino = serial.Serial('COM3', 9600)\n",
    "time.sleep(2)  # Give the connection a second to initialize\n",
    "\n",
    "# Initialize Mediapipe FaceMesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(rgb_frame)\n",
    "        annotated_frame = frame.copy()\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for landmarks in results.multi_face_landmarks:\n",
    "                # Get lip landmarks\n",
    "                upper_lip_y = landmarks.landmark[61].y\n",
    "                lower_lip_y = landmarks.landmark[17].y\n",
    "\n",
    "                # Calculate distance and dynamic threshold\n",
    "                lip_distance = abs(upper_lip_y - lower_lip_y)\n",
    "                left_eye = landmarks.landmark[33]\n",
    "                right_eye = landmarks.landmark[263]\n",
    "                eye_distance = abs(left_eye.x - right_eye.x)\n",
    "                threshold = 0.025 + (eye_distance * 0.1)\n",
    "\n",
    "                # Determine mouth status\n",
    "                if lip_distance > threshold:\n",
    "                    mouth_status = \"Mouth Open\"\n",
    "                    arduino.write(b'1')  # Send signal to Arduino\n",
    "                else:\n",
    "                    mouth_status = \"Mouth Closed\"\n",
    "                    arduino.write(b'0')  # Send signal to Arduino\n",
    "\n",
    "                # Display mouth status\n",
    "                cv2.putText(annotated_frame, mouth_status, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(\"Mouth Open/Closed Detection\", annotated_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "arduino.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b87c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe7d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360c35c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf9b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d7471b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d13f439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a86af59",
   "metadata": {},
   "source": [
    "### COMPLETE PYTHON CODE CONTROL SIGNAL FOR 4DOF ROBOTIC ARM USING MOUTH, EYES AND EYEBROWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59003235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import serial\n",
    "import time\n",
    "\n",
    "\n",
    "# Initialize serial communication with Arduino\n",
    "arduino = serial.Serial('COM3', 9600)\n",
    "time.sleep(2)  # Allow time for the connection to initialize\n",
    "\n",
    "# Initialize Mediapipe FaceMesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Webcam capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "claw_state = False  # False: Closed, True: Open\n",
    "blink_detected = False  # Tracks if blink was detected in the previous frame\n",
    "\n",
    "# Eyebrow landmark indices\n",
    "LEFT_BROW = [46, 53, 52, 65, 55, 63, 105, 66, 107]\n",
    "RIGHT_BROW = [276, 283, 282, 295, 285, 293, 334, 296, 336]\n",
    "\n",
    "# Function to calculate the gaze direction\n",
    "def calculate_gaze_direction(iris_center, eye_corners):\n",
    "    left_corner = eye_corners[0]\n",
    "    right_corner = eye_corners[1]\n",
    "    horizontal_ratio = (iris_center.x - left_corner.x) / (right_corner.x - left_corner.x)\n",
    "    return horizontal_ratio\n",
    "\n",
    "# Function to calculate blinking\n",
    "def is_blinking(eye_landmarks, threshold=0.2):\n",
    "    top = np.array([eye_landmarks[1].x, eye_landmarks[1].y])\n",
    "    bottom = np.array([eye_landmarks[2].x, eye_landmarks[2].y])\n",
    "    left = np.array([eye_landmarks[0].x, eye_landmarks[0].y])\n",
    "    right = np.array([eye_landmarks[3].x, eye_landmarks[3].y])\n",
    "\n",
    "    vertical_distance = np.linalg.norm(top - bottom)\n",
    "    horizontal_distance = np.linalg.norm(left - right)\n",
    "\n",
    "    blink_ratio = vertical_distance / horizontal_distance\n",
    "    return blink_ratio < threshold\n",
    "\n",
    "# Function to calculate the eyebrow movement (detect upward movement only)\n",
    "def calculate_eyebrow_movement(landmarks, left_brow_indices, right_brow_indices, baseline, movement_threshold):\n",
    "    left_brow_y = np.mean([landmarks[i][1] for i in left_brow_indices])\n",
    "    right_brow_y = np.mean([landmarks[i][1] for i in right_brow_indices])\n",
    "    avg_brow_y = (left_brow_y + right_brow_y) / 2\n",
    "\n",
    "    if baseline is None:\n",
    "        baseline = avg_brow_y\n",
    "        return \"Neutral\", baseline\n",
    "\n",
    "    if avg_brow_y < baseline - movement_threshold:\n",
    "        return \"Up\", baseline\n",
    "    else:\n",
    "        baseline = 0.9 * baseline + 0.1 * avg_brow_y\n",
    "        return \"Neutral\", baseline\n",
    "\n",
    "# Initialize baseline and movement threshold for eyebrow detection\n",
    "baseline_position = None\n",
    "movement_threshold = 0.01\n",
    "\n",
    "# Function to detect mouth open/closed status\n",
    "def detect_mouth_status(landmarks):\n",
    "    upper_lip_y = landmarks.landmark[61].y\n",
    "    lower_lip_y = landmarks.landmark[17].y\n",
    "    lip_distance = abs(upper_lip_y - lower_lip_y)\n",
    "    \n",
    "    left_eye = landmarks.landmark[33]\n",
    "    right_eye = landmarks.landmark[263]\n",
    "    eye_distance = abs(left_eye.x - right_eye.x)\n",
    "    \n",
    "    threshold = 0.025 + (eye_distance * 0.1)\n",
    "    \n",
    "    if lip_distance > threshold:\n",
    "        return \"Mouth Open\"\n",
    "    else:\n",
    "        return \"Mouth Closed\"\n",
    "\n",
    "# Function to process frames\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "\n",
    "    gaze_direction = \"Unknown\"\n",
    "    current_blink = False\n",
    "    mouth_status = \"Mouth Closed\"\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Iris and gaze detection\n",
    "            left_iris = face_landmarks.landmark[468]\n",
    "            right_iris = face_landmarks.landmark[473]\n",
    "\n",
    "            left_eye_corners = [face_landmarks.landmark[33], face_landmarks.landmark[133]]\n",
    "            right_eye_corners = [face_landmarks.landmark[362], face_landmarks.landmark[263]]\n",
    "\n",
    "            left_gaze_ratio = calculate_gaze_direction(left_iris, left_eye_corners)\n",
    "            right_gaze_ratio = calculate_gaze_direction(right_iris, right_eye_corners)\n",
    "            avg_gaze_ratio = (left_gaze_ratio + right_gaze_ratio) / 2\n",
    "\n",
    "            # Adjust thresholds for gaze direction\n",
    "            if avg_gaze_ratio < 0.35:\n",
    "                gaze_direction = \"LEFT\"\n",
    "                arduino.write(b'L\\n')  # Send 'L' to Arduino for left movement\n",
    "            elif avg_gaze_ratio > 0.65:\n",
    "                gaze_direction = \"RIGHT\"\n",
    "                arduino.write(b'R\\n')  # Send 'R' to Arduino for right movement\n",
    "            else:\n",
    "                gaze_direction = \"CENTER\"\n",
    "                arduino.write(b'C\\n')  # Send 'C' to Arduino for center position\n",
    "\n",
    "            # Eye blink detection\n",
    "            left_eye_landmarks = [\n",
    "                face_landmarks.landmark[133],  # Left corner\n",
    "                face_landmarks.landmark[159],  # Top\n",
    "                face_landmarks.landmark[145],  # Bottom\n",
    "                face_landmarks.landmark[33],   # Right corner\n",
    "            ]\n",
    "            right_eye_landmarks = [\n",
    "                face_landmarks.landmark[362],  # Left corner\n",
    "                face_landmarks.landmark[386],  # Top\n",
    "                face_landmarks.landmark[374],  # Bottom\n",
    "                face_landmarks.landmark[263],  # Right corner\n",
    "            ]\n",
    "            left_blinking = is_blinking(left_eye_landmarks)\n",
    "            right_blinking = is_blinking(right_eye_landmarks)\n",
    "            current_blink = left_blinking or right_blinking\n",
    "\n",
    "            # Handle blink state for claw control\n",
    "            if current_blink and not blink_detected:\n",
    "                blink_detected = True\n",
    "                claw_state = not claw_state  # Toggle claw state\n",
    "                if claw_state:\n",
    "                    arduino.write(b'OPEN\\n')  # Open claw\n",
    "                else:\n",
    "                    arduino.write(b'CLOSE\\n')  # Close claw\n",
    "            elif not current_blink:\n",
    "                blink_detected = False\n",
    "\n",
    "            # Detect eyebrow movement\n",
    "            eyebrow_state, baseline_position = calculate_eyebrow_movement(\n",
    "                [(lm.x, lm.y, lm.z) for lm in face_landmarks.landmark],\n",
    "                LEFT_BROW, RIGHT_BROW, baseline_position, movement_threshold\n",
    "            )\n",
    "\n",
    "            # Send commands to Arduino based on eyebrow state\n",
    "            if eyebrow_state == \"Up\":\n",
    "                arduino.write(b\"UP\\n\")  # Send \"UP\" command\n",
    "            elif eyebrow_state == \"Neutral\":\n",
    "                arduino.write(b\"DOWN\\n\")  # Send \"DOWN\" command\n",
    "\n",
    "            # Detect mouth status\n",
    "            mouth_status = detect_mouth_status(face_landmarks)\n",
    "\n",
    "            # Send mouth status to Arduino\n",
    "            if mouth_status == \"Mouth Open\":\n",
    "                arduino.write(b'EXTEND\\n')  # Send signal to Arduino\n",
    "            else:\n",
    "                arduino.write(b'RETRACT\\n')  # Send signal to Arduino\n",
    "\n",
    "            # Draw red dots for iris\n",
    "            for landmark in [left_iris, right_iris]:\n",
    "                x = int(landmark.x * frame.shape[1])\n",
    "                y = int(landmark.y * frame.shape[0])\n",
    "                cv2.circle(frame, (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "            # Display the gaze direction, claw state, eyebrow, and mouth status on the frame\n",
    "            cv2.putText(frame, f\"Gaze: {gaze_direction}\", (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Claw State: {'Open' if claw_state else 'Closed'}\", (30, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "            cv2.putText(frame, f\"Eyebrow Movement: {eyebrow_state}\", (50, 130), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Mouth Status: {mouth_status}\", (50, 170), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "    # Show the output frame\n",
    "    cv2.imshow(\"Face Tracking\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "arduino.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a807fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68513799",
   "metadata": {},
   "source": [
    "### COMPLETE FACIAL GESTURE DETECTION (NO ARDUINO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e588ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Mediapipe FaceMesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Webcam capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "claw_state = False  # False: Closed, True: Open\n",
    "blink_detected = False  # Tracks if blink was detected in the previous frame\n",
    "\n",
    "# Eyebrow landmark indices\n",
    "LEFT_BROW = [46, 53, 52, 65, 55, 63, 105, 66, 107]\n",
    "RIGHT_BROW = [276, 283, 282, 295, 285, 293, 334, 296, 336]\n",
    "\n",
    "# Function to calculate the gaze direction\n",
    "def calculate_gaze_direction(iris_center, eye_corners):\n",
    "    left_corner = eye_corners[0]\n",
    "    right_corner = eye_corners[1]\n",
    "    horizontal_ratio = (iris_center.x - left_corner.x) / (right_corner.x - left_corner.x)\n",
    "    return horizontal_ratio\n",
    "\n",
    "# Function to calculate blinking\n",
    "def is_blinking(eye_landmarks, threshold=0.2):\n",
    "    top = np.array([eye_landmarks[1].x, eye_landmarks[1].y])\n",
    "    bottom = np.array([eye_landmarks[2].x, eye_landmarks[2].y])\n",
    "    left = np.array([eye_landmarks[0].x, eye_landmarks[0].y])\n",
    "    right = np.array([eye_landmarks[3].x, eye_landmarks[3].y])\n",
    "\n",
    "    vertical_distance = np.linalg.norm(top - bottom)\n",
    "    horizontal_distance = np.linalg.norm(left - right)\n",
    "\n",
    "    blink_ratio = vertical_distance / horizontal_distance\n",
    "    return blink_ratio < threshold\n",
    "\n",
    "# Function to calculate the eyebrow movement (detect upward movement only)\n",
    "def calculate_eyebrow_movement(landmarks, left_brow_indices, right_brow_indices, baseline, movement_threshold):\n",
    "    left_brow_y = np.mean([landmarks[i][1] for i in left_brow_indices])\n",
    "    right_brow_y = np.mean([landmarks[i][1] for i in right_brow_indices])\n",
    "    avg_brow_y = (left_brow_y + right_brow_y) / 2\n",
    "\n",
    "    if baseline is None:\n",
    "        baseline = avg_brow_y\n",
    "        return \"Neutral\", baseline\n",
    "\n",
    "    if avg_brow_y < baseline - movement_threshold:\n",
    "        return \"Up\", baseline\n",
    "    else:\n",
    "        baseline = 0.9 * baseline + 0.1 * avg_brow_y\n",
    "        return \"Neutral\", baseline\n",
    "\n",
    "# Initialize baseline and movement threshold for eyebrow detection\n",
    "baseline_position = None\n",
    "movement_threshold = 0.01\n",
    "\n",
    "# Function to detect mouth open/closed status\n",
    "def detect_mouth_status(landmarks):\n",
    "    upper_lip_y = landmarks.landmark[61].y\n",
    "    lower_lip_y = landmarks.landmark[17].y\n",
    "    lip_distance = abs(upper_lip_y - lower_lip_y)\n",
    "    \n",
    "    left_eye = landmarks.landmark[33]\n",
    "    right_eye = landmarks.landmark[263]\n",
    "    eye_distance = abs(left_eye.x - right_eye.x)\n",
    "    \n",
    "    threshold = 0.025 + (eye_distance * 0.1)\n",
    "    \n",
    "    if lip_distance > threshold:\n",
    "        return \"Mouth Open\"\n",
    "    else:\n",
    "        return \"Mouth Closed\"\n",
    "\n",
    "# Process webcam frames\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "\n",
    "    gaze_direction = \"Unknown\"\n",
    "    current_blink = False\n",
    "    mouth_status = \"Mouth Closed\"\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Iris and gaze detection\n",
    "            left_iris = face_landmarks.landmark[468]\n",
    "            right_iris = face_landmarks.landmark[473]\n",
    "\n",
    "            left_eye_corners = [face_landmarks.landmark[33], face_landmarks.landmark[133]]\n",
    "            right_eye_corners = [face_landmarks.landmark[362], face_landmarks.landmark[263]]\n",
    "\n",
    "            left_gaze_ratio = calculate_gaze_direction(left_iris, left_eye_corners)\n",
    "            right_gaze_ratio = calculate_gaze_direction(right_iris, right_eye_corners)\n",
    "            avg_gaze_ratio = (left_gaze_ratio + right_gaze_ratio) / 2\n",
    "\n",
    "            if avg_gaze_ratio < 0.35:\n",
    "                gaze_direction = \"LEFT\"\n",
    "            elif avg_gaze_ratio > 0.65:\n",
    "                gaze_direction = \"RIGHT\"\n",
    "            else:\n",
    "                gaze_direction = \"CENTER\"\n",
    "\n",
    "            # Eye blink detection\n",
    "            left_eye_landmarks = [\n",
    "                face_landmarks.landmark[133],  # Left corner\n",
    "                face_landmarks.landmark[159],  # Top\n",
    "                face_landmarks.landmark[145],  # Bottom\n",
    "                face_landmarks.landmark[33],   # Right corner\n",
    "            ]\n",
    "            right_eye_landmarks = [\n",
    "                face_landmarks.landmark[362],  # Left corner\n",
    "                face_landmarks.landmark[386],  # Top\n",
    "                face_landmarks.landmark[374],  # Bottom\n",
    "                face_landmarks.landmark[263],  # Right corner\n",
    "            ]\n",
    "            left_blinking = is_blinking(left_eye_landmarks)\n",
    "            right_blinking = is_blinking(right_eye_landmarks)\n",
    "            current_blink = left_blinking or right_blinking\n",
    "\n",
    "            # Detect eyebrow movement\n",
    "            eyebrow_state, baseline_position = calculate_eyebrow_movement(\n",
    "                [(lm.x, lm.y, lm.z) for lm in face_landmarks.landmark],\n",
    "                LEFT_BROW, RIGHT_BROW, baseline_position, movement_threshold\n",
    "            )\n",
    "\n",
    "            # Detect mouth status\n",
    "            mouth_status = detect_mouth_status(face_landmarks)\n",
    "\n",
    "            # Draw red dots for iris\n",
    "            for landmark in [left_iris, right_iris]:\n",
    "                x = int(landmark.x * frame.shape[1])\n",
    "                y = int(landmark.y * frame.shape[0])\n",
    "                cv2.circle(frame, (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "            # Display the gaze direction, blink status, eyebrow, and mouth status on the frame\n",
    "            cv2.putText(frame, f\"Gaze: {gaze_direction}\", (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Blink: {'Detected' if current_blink else 'Not Detected'}\", (30, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "            cv2.putText(frame, f\"Eyebrow Movement: {eyebrow_state}\", (50, 130), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Mouth Status: {mouth_status}\", (50, 170), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "    # Show the output frame\n",
    "    cv2.imshow(\"Face Tracking\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290eb3da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dc81391",
   "metadata": {},
   "source": [
    "### COMPLETE CODE WITH 2 VIDEO FEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ca0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import serial\n",
    "import time\n",
    "\n",
    "# Initialize serial communication with Arduino\n",
    "arduino = serial.Serial('COM3', 9600)\n",
    "time.sleep(2)  # Allow time for the connection to initialize\n",
    "\n",
    "# Initialize Mediapipe FaceMesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Webcam capture for face control\n",
    "cap1 = cv2.VideoCapture(0)\n",
    "\n",
    "# Webcam capture for second camera (bottom video)\n",
    "cap2 = cv2.VideoCapture(1)\n",
    "\n",
    "claw_state = False  # False: Closed, True: Open\n",
    "blink_detected = False  # Tracks if blink was detected in the previous frame\n",
    "\n",
    "# Eyebrow landmark indices\n",
    "LEFT_BROW = [46, 53, 52, 65, 55, 63, 105, 66, 107]\n",
    "RIGHT_BROW = [276, 283, 282, 295, 285, 293, 334, 296, 336]\n",
    "\n",
    "# Function to calculate the gaze direction\n",
    "def calculate_gaze_direction(iris_center, eye_corners):\n",
    "    left_corner = eye_corners[0]\n",
    "    right_corner = eye_corners[1]\n",
    "    horizontal_ratio = (iris_center.x - left_corner.x) / (right_corner.x - left_corner.x)\n",
    "    return horizontal_ratio\n",
    "\n",
    "# Function to calculate blinking\n",
    "def is_blinking(eye_landmarks, threshold=0.2):\n",
    "    top = np.array([eye_landmarks[1].x, eye_landmarks[1].y])\n",
    "    bottom = np.array([eye_landmarks[2].x, eye_landmarks[2].y])\n",
    "    left = np.array([eye_landmarks[0].x, eye_landmarks[0].y])\n",
    "    right = np.array([eye_landmarks[3].x, eye_landmarks[3].y])\n",
    "\n",
    "    vertical_distance = np.linalg.norm(top - bottom)\n",
    "    horizontal_distance = np.linalg.norm(left - right)\n",
    "\n",
    "    blink_ratio = vertical_distance / horizontal_distance\n",
    "    return blink_ratio < threshold\n",
    "\n",
    "# Function to calculate the eyebrow movement (detect upward movement only)\n",
    "def calculate_eyebrow_movement(landmarks, left_brow_indices, right_brow_indices, baseline, movement_threshold):\n",
    "    left_brow_y = np.mean([landmarks[i][1] for i in left_brow_indices])\n",
    "    right_brow_y = np.mean([landmarks[i][1] for i in right_brow_indices])\n",
    "    avg_brow_y = (left_brow_y + right_brow_y) / 2\n",
    "\n",
    "    if baseline is None:\n",
    "        baseline = avg_brow_y\n",
    "        return \"Neutral\", baseline\n",
    "\n",
    "    if avg_brow_y < baseline - movement_threshold:\n",
    "        return \"Up\", baseline\n",
    "    else:\n",
    "        baseline = 0.9 * baseline + 0.1 * avg_brow_y\n",
    "        return \"Neutral\", baseline\n",
    "\n",
    "# Initialize baseline and movement threshold for eyebrow detection\n",
    "baseline_position = None\n",
    "movement_threshold = 0.01\n",
    "\n",
    "# Function to detect mouth open/closed status\n",
    "def detect_mouth_status(landmarks):\n",
    "    upper_lip_y = landmarks.landmark[61].y\n",
    "    lower_lip_y = landmarks.landmark[17].y\n",
    "    lip_distance = abs(upper_lip_y - lower_lip_y)\n",
    "    \n",
    "    left_eye = landmarks.landmark[33]\n",
    "    right_eye = landmarks.landmark[263]\n",
    "    eye_distance = abs(left_eye.x - right_eye.x)\n",
    "    \n",
    "    threshold = 0.025 + (eye_distance * 0.1)\n",
    "    \n",
    "    if lip_distance > threshold:\n",
    "        return \"Mouth Open\"\n",
    "    else:\n",
    "        return \"Mouth Closed\"\n",
    "\n",
    "# Function to process frames\n",
    "while cap1.isOpened() and cap2.isOpened():\n",
    "    success1, frame1 = cap1.read()\n",
    "    success2, frame2 = cap2.read()\n",
    "    \n",
    "    if not success1 or not success2:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "\n",
    "    frame1 = cv2.flip(frame1, 1)\n",
    "    frame2 = cv2.flip(frame2, 1)\n",
    "    frame1_rgb = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(frame1_rgb)\n",
    "\n",
    "    gaze_direction = \"Unknown\"\n",
    "    current_blink = False\n",
    "    mouth_status = \"Mouth Closed\"\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Iris and gaze detection\n",
    "            left_iris = face_landmarks.landmark[468]\n",
    "            right_iris = face_landmarks.landmark[473]\n",
    "\n",
    "            left_eye_corners = [face_landmarks.landmark[33], face_landmarks.landmark[133]]\n",
    "            right_eye_corners = [face_landmarks.landmark[362], face_landmarks.landmark[263]]\n",
    "\n",
    "            left_gaze_ratio = calculate_gaze_direction(left_iris, left_eye_corners)\n",
    "            right_gaze_ratio = calculate_gaze_direction(right_iris, right_eye_corners)\n",
    "            avg_gaze_ratio = (left_gaze_ratio + right_gaze_ratio) / 2\n",
    "\n",
    "            # Adjust thresholds for gaze direction\n",
    "            if avg_gaze_ratio < 0.35:\n",
    "                gaze_direction = \"LEFT\"\n",
    "                arduino.write(b'L\\n')  # Send 'L' to Arduino for left movement\n",
    "            elif avg_gaze_ratio > 0.65:\n",
    "                gaze_direction = \"RIGHT\"\n",
    "                arduino.write(b'R\\n')  # Send 'R' to Arduino for right movement\n",
    "            else:\n",
    "                gaze_direction = \"CENTER\"\n",
    "                arduino.write(b'C\\n')  # Send 'C' to Arduino for center position\n",
    "\n",
    "            # Eye blink detection\n",
    "            left_eye_landmarks = [\n",
    "                face_landmarks.landmark[133],  # Left corner\n",
    "                face_landmarks.landmark[159],  # Top\n",
    "                face_landmarks.landmark[145],  # Bottom\n",
    "                face_landmarks.landmark[33],   # Right corner\n",
    "            ]\n",
    "            right_eye_landmarks = [\n",
    "                face_landmarks.landmark[362],  # Left corner\n",
    "                face_landmarks.landmark[386],  # Top\n",
    "                face_landmarks.landmark[374],  # Bottom\n",
    "                face_landmarks.landmark[263],  # Right corner\n",
    "            ]\n",
    "            left_blinking = is_blinking(left_eye_landmarks)\n",
    "            right_blinking = is_blinking(right_eye_landmarks)\n",
    "            current_blink = left_blinking or right_blinking\n",
    "\n",
    "            # Handle blink state for claw control\n",
    "            if current_blink and not blink_detected:\n",
    "                blink_detected = True\n",
    "                claw_state = not claw_state  # Toggle claw state\n",
    "                if claw_state:\n",
    "                    arduino.write(b'OPEN\\n')  # Open claw\n",
    "                else:\n",
    "                    arduino.write(b'CLOSE\\n')  # Close claw\n",
    "            elif not current_blink:\n",
    "                blink_detected = False\n",
    "\n",
    "            # Detect eyebrow movement\n",
    "            eyebrow_state, baseline_position = calculate_eyebrow_movement(\n",
    "                [(lm.x, lm.y, lm.z) for lm in face_landmarks.landmark],\n",
    "                LEFT_BROW, RIGHT_BROW, baseline_position, movement_threshold\n",
    "            )\n",
    "\n",
    "            # Send commands to Arduino based on eyebrow state\n",
    "            if eyebrow_state == \"Up\":\n",
    "                arduino.write(b\"UP\\n\")  # Send \"UP\" command\n",
    "            elif eyebrow_state == \"Neutral\":\n",
    "                arduino.write(b\"DOWN\\n\")  # Send \"DOWN\" command\n",
    "\n",
    "            # Detect mouth status\n",
    "            mouth_status = detect_mouth_status(face_landmarks)\n",
    "\n",
    "            # Send mouth status to Arduino\n",
    "            if mouth_status == \"Mouth Open\":\n",
    "                arduino.write(b'EXTEND\\n')  # Send signal to Arduino\n",
    "            else:\n",
    "                arduino.write(b'RETRACT\\n')  # Send signal to Arduino\n",
    "\n",
    "            # Draw the text information on the frame\n",
    "            cv2.putText(frame1, f\"Gaze: {gaze_direction}\", (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 1)\n",
    "            cv2.putText(frame1, f\"Claw: {'Open' if claw_state else 'Closed'}\", (30, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 1)\n",
    "            cv2.putText(frame1, f\"Eyebrow: {eyebrow_state}\", (30, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 1)\n",
    "            cv2.putText(frame1, f\"Mouth: {mouth_status}\", (30, 170), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 1)\n",
    "\n",
    "    # Stack the two frames vertically\n",
    "    stacked_frames = np.vstack((frame1, frame2))\n",
    "\n",
    "    # Show the output\n",
    "    cv2.imshow(\"Face Tracking and Camera Feed\", stacked_frames)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "cap1.release()\n",
    "cap2.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706b6051",
   "metadata": {},
   "source": [
    "### COMPLETE CODE WITH 2 VIDEO FEED UPGRADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84195097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import serial\n",
    "import time\n",
    "\n",
    "# Initialize serial communication with Arduino\n",
    "arduino = serial.Serial('COM3', 9600)\n",
    "time.sleep(2)  # Allow time for the connection to initialize\n",
    "\n",
    "# Initialize Mediapipe FaceMesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Webcam capture for face control\n",
    "cap1 = cv2.VideoCapture(0)\n",
    "\n",
    "# Webcam capture for second camera (bottom video)\n",
    "cap2 = cv2.VideoCapture(1)\n",
    "\n",
    "claw_state = False  # False: Closed, True: Open\n",
    "blink_detected = False  # Tracks if blink was detected in the previous frame\n",
    "\n",
    "# Eyebrow landmark indices\n",
    "LEFT_BROW = [46, 53, 52, 65, 55, 63, 105, 66, 107]\n",
    "RIGHT_BROW = [276, 283, 282, 295, 285, 293, 334, 296, 336]\n",
    "\n",
    "# Function to calculate the gaze direction\n",
    "def calculate_gaze_direction(iris_center, eye_corners):\n",
    "    left_corner = eye_corners[0]\n",
    "    right_corner = eye_corners[1]\n",
    "    horizontal_ratio = (iris_center.x - left_corner.x) / (right_corner.x - left_corner.x)\n",
    "    return horizontal_ratio\n",
    "\n",
    "# Function to calculate blinking\n",
    "def is_blinking(eye_landmarks, threshold=0.2):\n",
    "    top = np.array([eye_landmarks[1].x, eye_landmarks[1].y])\n",
    "    bottom = np.array([eye_landmarks[2].x, eye_landmarks[2].y])\n",
    "    left = np.array([eye_landmarks[0].x, eye_landmarks[0].y])\n",
    "    right = np.array([eye_landmarks[3].x, eye_landmarks[3].y])\n",
    "\n",
    "    vertical_distance = np.linalg.norm(top - bottom)\n",
    "    horizontal_distance = np.linalg.norm(left - right)\n",
    "\n",
    "    blink_ratio = vertical_distance / horizontal_distance\n",
    "    return blink_ratio < threshold\n",
    "\n",
    "# Function to calculate the eyebrow movement (detect upward movement only)\n",
    "def calculate_eyebrow_movement(landmarks, left_brow_indices, right_brow_indices, baseline, movement_threshold):\n",
    "    left_brow_y = np.mean([landmarks[i][1] for i in left_brow_indices])\n",
    "    right_brow_y = np.mean([landmarks[i][1] for i in right_brow_indices])\n",
    "    avg_brow_y = (left_brow_y + right_brow_y) / 2\n",
    "\n",
    "    if baseline is None:\n",
    "        baseline = avg_brow_y\n",
    "        return \"Neutral\", baseline\n",
    "\n",
    "    if avg_brow_y < baseline - movement_threshold:\n",
    "        return \"Up\", baseline\n",
    "    else:\n",
    "        baseline = 0.9 * baseline + 0.1 * avg_brow_y\n",
    "        return \"Neutral\", baseline\n",
    "\n",
    "# Initialize baseline and movement threshold for eyebrow detection\n",
    "baseline_position = None\n",
    "movement_threshold = 0.01\n",
    "\n",
    "# Function to detect mouth open/closed status\n",
    "def detect_mouth_status(landmarks):\n",
    "    upper_lip_y = landmarks.landmark[61].y\n",
    "    lower_lip_y = landmarks.landmark[17].y\n",
    "    lip_distance = abs(upper_lip_y - lower_lip_y)\n",
    "    \n",
    "    left_eye = landmarks.landmark[33]\n",
    "    right_eye = landmarks.landmark[263]\n",
    "    eye_distance = abs(left_eye.x - right_eye.x)\n",
    "    \n",
    "    threshold = 0.025 + (eye_distance * 0.1)\n",
    "    \n",
    "    if lip_distance > threshold:\n",
    "        return \"Mouth Open\"\n",
    "    else:\n",
    "        return \"Mouth Closed\"\n",
    "\n",
    "# Function to process frames\n",
    "while cap1.isOpened() and cap2.isOpened():\n",
    "    success1, frame1 = cap1.read()\n",
    "    success2, frame2 = cap2.read()\n",
    "    \n",
    "    if not success1 or not success2:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "\n",
    "    frame1 = cv2.flip(frame1, 1)\n",
    "    frame2 = cv2.flip(frame2, 1)\n",
    "    \n",
    "    # Resize the frames to change the video display size\n",
    "    frame1 = cv2.resize(frame1, (640, 480))  # Smaller face control feed\n",
    "    frame2 = cv2.resize(frame2, (640, 480))  # Resize second feed to match width\n",
    "    \n",
    "    frame1_rgb = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(frame1_rgb)\n",
    "\n",
    "    gaze_direction = \"Unknown\"\n",
    "    current_blink = False\n",
    "    mouth_status = \"Mouth Closed\"\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Iris and gaze detection\n",
    "            left_iris = face_landmarks.landmark[468]\n",
    "            right_iris = face_landmarks.landmark[473]\n",
    "\n",
    "            left_eye_corners = [face_landmarks.landmark[33], face_landmarks.landmark[133]]\n",
    "            right_eye_corners = [face_landmarks.landmark[362], face_landmarks.landmark[263]]\n",
    "\n",
    "            left_gaze_ratio = calculate_gaze_direction(left_iris, left_eye_corners)\n",
    "            right_gaze_ratio = calculate_gaze_direction(right_iris, right_eye_corners)\n",
    "            avg_gaze_ratio = (left_gaze_ratio + right_gaze_ratio) / 2\n",
    "\n",
    "            # Adjust thresholds for gaze direction\n",
    "            if avg_gaze_ratio < 0.35:\n",
    "                gaze_direction = \"LEFT\"\n",
    "                arduino.write(b'L\\n')  # Send 'L' to Arduino for left movement\n",
    "            elif avg_gaze_ratio > 0.65:\n",
    "                gaze_direction = \"RIGHT\"\n",
    "                arduino.write(b'R\\n')  # Send 'R' to Arduino for right movement\n",
    "            else:\n",
    "                gaze_direction = \"CENTER\"\n",
    "                arduino.write(b'C\\n')  # Send 'C' to Arduino for center position\n",
    "\n",
    "            # Eye blink detection\n",
    "            left_eye_landmarks = [\n",
    "                face_landmarks.landmark[133],  # Left corner\n",
    "                face_landmarks.landmark[159],  # Top\n",
    "                face_landmarks.landmark[145],  # Bottom\n",
    "                face_landmarks.landmark[33],   # Right corner\n",
    "            ]\n",
    "            right_eye_landmarks = [\n",
    "                face_landmarks.landmark[362],  # Left corner\n",
    "                face_landmarks.landmark[386],  # Top\n",
    "                face_landmarks.landmark[374],  # Bottom\n",
    "                face_landmarks.landmark[263],  # Right corner\n",
    "            ]\n",
    "            left_blinking = is_blinking(left_eye_landmarks)\n",
    "            right_blinking = is_blinking(right_eye_landmarks)\n",
    "            current_blink = left_blinking or right_blinking\n",
    "\n",
    "            # Handle blink state for claw control\n",
    "            if current_blink and not blink_detected:\n",
    "                blink_detected = True\n",
    "                claw_state = not claw_state  # Toggle claw state\n",
    "                if claw_state:\n",
    "                    arduino.write(b'OPEN\\n')  # Open claw\n",
    "                else:\n",
    "                    arduino.write(b'CLOSE\\n')  # Close claw\n",
    "            elif not current_blink:\n",
    "                blink_detected = False\n",
    "\n",
    "            # Detect eyebrow movement\n",
    "            eyebrow_state, baseline_position = calculate_eyebrow_movement(\n",
    "                [(lm.x, lm.y, lm.z) for lm in face_landmarks.landmark],\n",
    "                LEFT_BROW, RIGHT_BROW, baseline_position, movement_threshold\n",
    "            )\n",
    "\n",
    "            # Send commands to Arduino based on eyebrow state\n",
    "            if eyebrow_state == \"Up\":\n",
    "                arduino.write(b\"UP\\n\")  # Send \"UP\" command\n",
    "            elif eyebrow_state == \"Neutral\":\n",
    "                arduino.write(b\"DOWN\\n\")  # Send \"DOWN\" command\n",
    "\n",
    "            # Detect mouth status\n",
    "            mouth_status = detect_mouth_status(face_landmarks)\n",
    "\n",
    "            # Send mouth status to Arduino\n",
    "            if mouth_status == \"Mouth Open\":\n",
    "                arduino.write(b'EXTEND\\n')  # Send signal to Arduino\n",
    "            else:\n",
    "                arduino.write(b'RETRACT\\n')  # Send signal to Arduino\n",
    "\n",
    "            # Draw the text information on the frame\n",
    "            cv2.putText(frame1, f\"Gaze: {gaze_direction}\", (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 1)\n",
    "            cv2.putText(frame1, f\"Claw: {'Open' if claw_state else 'Closed'}\", (30, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 1)\n",
    "            cv2.putText(frame1, f\"Eyebrow: {eyebrow_state}\", (30, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 1)\n",
    "            cv2.putText(frame1, f\"Mouth: {mouth_status}\", (30, 170), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 1)\n",
    "\n",
    "    # Stack the two frames vertically after resizing them to match the width\n",
    "    stacked_frames = np.vstack((frame1, frame2))\n",
    "\n",
    "    # Show the output\n",
    "    cv2.imshow(\"Face Tracking and Control\", stacked_frames)\n",
    "\n",
    "    # Exit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the resources\n",
    "cap1.release()\n",
    "cap2.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8134e4",
   "metadata": {},
   "source": [
    "### FACE GESTURE CONTROLLED ROBOTIC ARM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f37ed5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial connection established.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import serial\n",
    "import time\n",
    "\n",
    "# Initialize serial communication with Arduino\n",
    "def initialize_serial(port, baud_rate=9600):\n",
    "    try:\n",
    "        arduino = serial.Serial(port, baud_rate)\n",
    "        time.sleep(2)  # Allow time for connection to initialize\n",
    "        print(\"Serial connection established.\")\n",
    "        return arduino\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing serial: {e}\")\n",
    "        return None\n",
    "\n",
    "# Initialize Mediapipe FaceMesh\n",
    "def initialize_face_mesh():\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    return mp_face_mesh.FaceMesh(refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Function to calculate gaze direction\n",
    "def calculate_gaze_direction(iris_center, eye_corners):\n",
    "    left_corner = eye_corners[0]\n",
    "    right_corner = eye_corners[1]\n",
    "    horizontal_ratio = (iris_center.x - left_corner.x) / (right_corner.x - left_corner.x)\n",
    "    return horizontal_ratio\n",
    "\n",
    "# Function to detect blinking\n",
    "def is_blinking(eye_landmarks, threshold=0.2):\n",
    "    top = np.array([eye_landmarks[1].x, eye_landmarks[1].y])\n",
    "    bottom = np.array([eye_landmarks[2].x, eye_landmarks[2].y])\n",
    "    left = np.array([eye_landmarks[0].x, eye_landmarks[0].y])\n",
    "    right = np.array([eye_landmarks[3].x, eye_landmarks[3].y])\n",
    "\n",
    "    vertical_distance = np.linalg.norm(top - bottom)\n",
    "    horizontal_distance = np.linalg.norm(left - right)\n",
    "\n",
    "    blink_ratio = vertical_distance / horizontal_distance\n",
    "    return blink_ratio < threshold\n",
    "\n",
    "# Function to detect mouth status\n",
    "def detect_mouth_status(landmarks):\n",
    "    upper_lip_y = landmarks.landmark[61].y\n",
    "    lower_lip_y = landmarks.landmark[17].y\n",
    "    lip_distance = abs(upper_lip_y - lower_lip_y)\n",
    "    \n",
    "    left_eye = landmarks.landmark[33]\n",
    "    right_eye = landmarks.landmark[263]\n",
    "    eye_distance = abs(left_eye.x - right_eye.x)\n",
    "    \n",
    "    threshold = 0.025 + (eye_distance * 0.1)\n",
    "    return \"Mouth Open\" if lip_distance > threshold else \"Mouth Closed\"\n",
    "\n",
    "# Function to calculate eyebrow movement\n",
    "def calculate_eyebrow_movement(landmarks, left_brow_indices, right_brow_indices, baseline, movement_threshold):\n",
    "    left_brow_y = np.mean([landmarks[i][1] for i in left_brow_indices])\n",
    "    right_brow_y = np.mean([landmarks[i][1] for i in right_brow_indices])\n",
    "    avg_brow_y = (left_brow_y + right_brow_y) / 2\n",
    "\n",
    "    if baseline is None:\n",
    "        baseline = avg_brow_y\n",
    "        return \"Neutral\", baseline\n",
    "\n",
    "    if avg_brow_y < baseline - movement_threshold:\n",
    "        return \"Eyebrows Raised\", baseline\n",
    "    else:\n",
    "        baseline = 0.9 * baseline + 0.1 * avg_brow_y\n",
    "        return \"Neutral\", baseline\n",
    "\n",
    "# Function to send commands to Arduino\n",
    "def send_command_to_arduino(arduino, command):\n",
    "    if arduino:\n",
    "        try:\n",
    "            arduino.write(f\"{command}\\n\".encode())\n",
    "        except Exception as e:\n",
    "            print(f\"Error sending command: {e}\")\n",
    "\n",
    "# Function to overlay detection results\n",
    "def overlay_text(frame, text, position, color=(0, 255, 0)):\n",
    "    cv2.putText(frame, text, position, cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2, cv2.LINE_AA)\n",
    "\n",
    "# Function to process face landmarks\n",
    "def process_face_landmarks(face_landmarks, arduino, baseline_position, movement_threshold, frame):\n",
    "    global blink_detected, claw_state\n",
    "    \n",
    "    LEFT_BROW = [46, 53, 52, 65, 55, 63, 105, 66, 107]\n",
    "    RIGHT_BROW = [276, 283, 282, 295, 285, 293, 334, 296, 336]\n",
    "    \n",
    "    # Gaze detection\n",
    "    left_iris = face_landmarks.landmark[468]\n",
    "    right_iris = face_landmarks.landmark[473]\n",
    "    left_eye_corners = [face_landmarks.landmark[33], face_landmarks.landmark[133]]\n",
    "    right_eye_corners = [face_landmarks.landmark[362], face_landmarks.landmark[263]]\n",
    "    \n",
    "    avg_gaze_ratio = (calculate_gaze_direction(left_iris, left_eye_corners) +\n",
    "                      calculate_gaze_direction(right_iris, right_eye_corners)) / 2\n",
    "    gaze_direction = \"Center\"\n",
    "    if avg_gaze_ratio < 0.35:\n",
    "        send_command_to_arduino(arduino, 'L')\n",
    "        gaze_direction = \"Left\"\n",
    "        gaze_color = (0, 0, 255)  # Red\n",
    "    elif avg_gaze_ratio > 0.65:\n",
    "        send_command_to_arduino(arduino, 'R')\n",
    "        gaze_direction = \"Right\"\n",
    "        gaze_color = (0, 0, 255)  # Red\n",
    "    else:\n",
    "        gaze_color = (0, 255, 0)  # Green (default)\n",
    "    overlay_text(frame, f\"Gaze: {gaze_direction}\", (10, 30), gaze_color)\n",
    "\n",
    "    # Blink detection and claw state\n",
    "    left_eye_landmarks = [face_landmarks.landmark[133], face_landmarks.landmark[159], face_landmarks.landmark[145], face_landmarks.landmark[33]]\n",
    "    right_eye_landmarks = [face_landmarks.landmark[362], face_landmarks.landmark[386], face_landmarks.landmark[374], face_landmarks.landmark[263]]\n",
    "    current_blink = is_blinking(left_eye_landmarks) or is_blinking(right_eye_landmarks)\n",
    "    if current_blink and not blink_detected:\n",
    "        blink_detected = True\n",
    "        claw_state = not claw_state\n",
    "        send_command_to_arduino(arduino, 'OPEN' if claw_state else 'CLOSE')\n",
    "    elif not current_blink:\n",
    "        blink_detected = False\n",
    "    claw_color = (0, 255, 0) if claw_state else (0, 0, 255)  # Green if open, Red if closed\n",
    "    overlay_text(frame, f\"Claw: {'Open' if claw_state else 'Closed'}\", (10, 60), claw_color)\n",
    "\n",
    "    # Eyebrow movement\n",
    "    eyebrow_state, baseline_position = calculate_eyebrow_movement(\n",
    "        [(lm.x, lm.y, lm.z) for lm in face_landmarks.landmark],\n",
    "        LEFT_BROW, RIGHT_BROW, baseline_position, movement_threshold\n",
    "    )\n",
    "    send_command_to_arduino(arduino, \"UP\" if eyebrow_state == \"Eyebrows Raised\" else \"DOWN\")\n",
    "    eyebrow_color = (0, 0, 255) if eyebrow_state == \"Eyebrows Raised\" else (0, 255, 0)  # Red if raised, Green if neutral\n",
    "    overlay_text(frame, f\"Eyebrows: {eyebrow_state}\", (10, 90), eyebrow_color)\n",
    "\n",
    "    # Mouth status\n",
    "    mouth_status = detect_mouth_status(face_landmarks)\n",
    "    send_command_to_arduino(arduino, 'EXTEND' if mouth_status == \"Mouth Open\" else 'RETRACT')\n",
    "    mouth_color = (0, 0, 255) if mouth_status == \"Mouth Open\" else (0, 255, 0)  # Red if open, Green if closed\n",
    "    overlay_text(frame, f\"Mouth: {mouth_status}\", (10, 120), mouth_color)\n",
    "\n",
    "    return baseline_position\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    global blink_detected, claw_state\n",
    "    blink_detected = False\n",
    "    claw_state = False\n",
    "    \n",
    "    # Initialize resources\n",
    "    arduino = initialize_serial('COM3')\n",
    "    face_mesh = initialize_face_mesh()\n",
    "    cap1 = cv2.VideoCapture(0)\n",
    "    cap2 = cv2.VideoCapture(1)\n",
    "    \n",
    "    baseline_position = None\n",
    "    movement_threshold = 0.01\n",
    "\n",
    "    while cap1.isOpened() and cap2.isOpened():\n",
    "        success1, frame1 = cap1.read()\n",
    "        success2, frame2 = cap2.read()\n",
    "        if not success1 or not success2:\n",
    "            print(\"Error reading frames.\")\n",
    "            break\n",
    "        \n",
    "        # Flip the frames horizontally for better visualization\n",
    "        frame1 = cv2.flip(frame1, 1)\n",
    "        frame2 = cv2.flip(frame2, 1)\n",
    "        \n",
    "        # Convert frames to RGB for processing\n",
    "        frame_rgb = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        results = face_mesh.process(frame_rgb)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                baseline_position = process_face_landmarks(face_landmarks, arduino, baseline_position, movement_threshold, frame1)\n",
    "\n",
    "        # Resize frames for better visualization\n",
    "        frame1_resized = cv2.resize(frame1, (640, 400))\n",
    "        frame2_resized = cv2.resize(frame2, (640, 400))\n",
    "\n",
    "        # Stack frames verticallyq\n",
    "        stacked_frame = np.vstack((frame1_resized, frame2_resized))\n",
    "\n",
    "        # Show the stacked frames with overlayed text\n",
    "        cv2.imshow(\"Feed\", stacked_frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap1.release()\n",
    "    cap2.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fa409b",
   "metadata": {},
   "source": [
    "### WITH LANDMARKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "589bea0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial connection established.\n"
     ]
    }
   ],
   "source": [
    "#### import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import serial\n",
    "import time\n",
    "\n",
    "# Initialize serial communication with Arduino\n",
    "def initialize_serial(port, baud_rate=9600):\n",
    "    try:\n",
    "        arduino = serial.Serial(port, baud_rate)\n",
    "        time.sleep(2)  # Allow time for connection to initialize\n",
    "        print(\"Serial connection established.\")\n",
    "        return arduino\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing serial: {e}\")\n",
    "        return None\n",
    "\n",
    "# Initialize Mediapipe FaceMesh\n",
    "def initialize_face_mesh():\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    return mp_face_mesh.FaceMesh(refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Function to calculate gaze direction\n",
    "def calculate_gaze_direction(iris_center, eye_corners):\n",
    "    left_corner = eye_corners[0]\n",
    "    right_corner = eye_corners[1]\n",
    "    horizontal_ratio = (iris_center.x - left_corner.x) / (right_corner.x - left_corner.x)\n",
    "    return horizontal_ratio\n",
    "\n",
    "# Function to detect blinking\n",
    "def is_blinking(eye_landmarks, threshold=0.2):\n",
    "    top = np.array([eye_landmarks[1].x, eye_landmarks[1].y])\n",
    "    bottom = np.array([eye_landmarks[2].x, eye_landmarks[2].y])\n",
    "    left = np.array([eye_landmarks[0].x, eye_landmarks[0].y])\n",
    "    right = np.array([eye_landmarks[3].x, eye_landmarks[3].y])\n",
    "\n",
    "    vertical_distance = np.linalg.norm(top - bottom)\n",
    "    horizontal_distance = np.linalg.norm(left - right)\n",
    "\n",
    "    blink_ratio = vertical_distance / horizontal_distance\n",
    "    return blink_ratio < threshold\n",
    "\n",
    "# Function to detect mouth status\n",
    "def detect_mouth_status(landmarks):\n",
    "    upper_lip_y = landmarks.landmark[61].y\n",
    "    lower_lip_y = landmarks.landmark[17].y\n",
    "    lip_distance = abs(upper_lip_y - lower_lip_y)\n",
    "    \n",
    "    left_eye = landmarks.landmark[33]\n",
    "    right_eye = landmarks.landmark[263]\n",
    "    eye_distance = abs(left_eye.x - right_eye.x)\n",
    "    \n",
    "    threshold = 0.025 + (eye_distance * 0.1)\n",
    "    return \"Mouth Open\" if lip_distance > threshold else \"Mouth Closed\"\n",
    "\n",
    "# Function to calculate eyebrow movement\n",
    "def calculate_eyebrow_movement(landmarks, left_brow_indices, right_brow_indices, baseline, movement_threshold):\n",
    "    left_brow_y = np.mean([landmarks[i][1] for i in left_brow_indices])\n",
    "    right_brow_y = np.mean([landmarks[i][1] for i in right_brow_indices])\n",
    "    avg_brow_y = (left_brow_y + right_brow_y) / 2\n",
    "\n",
    "    if baseline is None:\n",
    "        baseline = avg_brow_y\n",
    "        return \"Neutral\", baseline\n",
    "\n",
    "    if avg_brow_y < baseline - movement_threshold:\n",
    "        return \"Eyebrows Raised\", baseline\n",
    "    else:\n",
    "        baseline = 0.9 * baseline + 0.1 * avg_brow_y\n",
    "        return \"Neutral\", baseline\n",
    "\n",
    "# Function to send commands to Arduino\n",
    "def send_command_to_arduino(arduino, command):\n",
    "    if arduino:\n",
    "        try:\n",
    "            arduino.write(f\"{command}\\n\".encode())\n",
    "        except Exception as e:\n",
    "            print(f\"Error sending command: {e}\")\n",
    "\n",
    "# Function to overlay detection results\n",
    "def overlay_text(frame, text, position, color=(0, 255, 0)):\n",
    "    cv2.putText(frame, text, position, cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2, cv2.LINE_AA)\n",
    "\n",
    "# Function to process face landmarks\n",
    "def process_face_landmarks(face_landmarks, arduino, baseline_position, movement_threshold, frame):\n",
    "    global blink_detected, claw_state\n",
    "    \n",
    "    LEFT_BROW = [46, 53, 52, 65, 55, 63, 105, 66, 107]\n",
    "    RIGHT_BROW = [276, 283, 282, 295, 285, 293, 334, 296, 336]\n",
    "    \n",
    "    # Gaze detection\n",
    "    left_iris = face_landmarks.landmark[468]\n",
    "    right_iris = face_landmarks.landmark[473]\n",
    "    left_eye_corners = [face_landmarks.landmark[33], face_landmarks.landmark[133]]\n",
    "    right_eye_corners = [face_landmarks.landmark[362], face_landmarks.landmark[263]]\n",
    "    \n",
    "    avg_gaze_ratio = (calculate_gaze_direction(left_iris, left_eye_corners) +\n",
    "                      calculate_gaze_direction(right_iris, right_eye_corners)) / 2\n",
    "    gaze_direction = \"Center\"\n",
    "    if avg_gaze_ratio < 0.35:\n",
    "        send_command_to_arduino(arduino, 'L')\n",
    "        gaze_direction = \"Left\"\n",
    "        gaze_color = (0, 0, 255)  # Red\n",
    "    elif avg_gaze_ratio > 0.65:\n",
    "        send_command_to_arduino(arduino, 'R')\n",
    "        gaze_direction = \"Right\"\n",
    "        gaze_color = (0, 0, 255)  # Red\n",
    "    else:\n",
    "        gaze_color = (0, 255, 0)  # Green (default)\n",
    "    overlay_text(frame, f\"Gaze: {gaze_direction}\", (10, 30), gaze_color)\n",
    "\n",
    "    # Blink detection and claw state\n",
    "    left_eye_landmarks = [face_landmarks.landmark[133], face_landmarks.landmark[159], face_landmarks.landmark[145], face_landmarks.landmark[33]]\n",
    "    right_eye_landmarks = [face_landmarks.landmark[362], face_landmarks.landmark[386], face_landmarks.landmark[374], face_landmarks.landmark[263]]\n",
    "    current_blink = is_blinking(left_eye_landmarks) or is_blinking(right_eye_landmarks)\n",
    "    if current_blink and not blink_detected:\n",
    "        blink_detected = True\n",
    "        claw_state = not claw_state\n",
    "        send_command_to_arduino(arduino, 'OPEN' if claw_state else 'CLOSE')\n",
    "    elif not current_blink:\n",
    "        blink_detected = False\n",
    "    claw_color = (0, 255, 0) if claw_state else (0, 0, 255)  # Green if open, Red if closed\n",
    "    overlay_text(frame, f\"Claw: {'Open' if claw_state else 'Closed'}\", (10, 60), claw_color)\n",
    "\n",
    "    # Eyebrow movement\n",
    "    eyebrow_state, baseline_position = calculate_eyebrow_movement(\n",
    "        [(lm.x, lm.y, lm.z) for lm in face_landmarks.landmark],\n",
    "        LEFT_BROW, RIGHT_BROW, baseline_position, movement_threshold\n",
    "    )\n",
    "    send_command_to_arduino(arduino, \"UP\" if eyebrow_state == \"Eyebrows Raised\" else \"DOWN\")\n",
    "    eyebrow_color = (0, 0, 255) if eyebrow_state == \"Eyebrows Raised\" else (0, 255, 0)  # Red if raised, Green if neutral\n",
    "    overlay_text(frame, f\"Eyebrows: {eyebrow_state}\", (10, 90), eyebrow_color)\n",
    "\n",
    "    # Mouth status\n",
    "    mouth_status = detect_mouth_status(face_landmarks)\n",
    "    send_command_to_arduino(arduino, 'EXTEND' if mouth_status == \"Mouth Open\" else 'RETRACT')\n",
    "    mouth_color = (0, 0, 255) if mouth_status == \"Mouth Open\" else (0, 255, 0)  # Red if open, Green if closed\n",
    "    overlay_text(frame, f\"Mouth: {mouth_status}\", (10, 120), mouth_color)\n",
    "\n",
    "    # Draw the pupil landmarks in red for both eyes\n",
    "    left_pupil_landmark = face_landmarks.landmark[468]  # Left pupil center\n",
    "    right_pupil_landmark = face_landmarks.landmark[473]  # Right pupil center\n",
    "    height, width, _ = frame.shape\n",
    "    \n",
    "    left_pupil_x, left_pupil_y = int(left_pupil_landmark.x * width), int(left_pupil_landmark.y * height)\n",
    "    right_pupil_x, right_pupil_y = int(right_pupil_landmark.x * width), int(right_pupil_landmark.y * height)\n",
    "    \n",
    "    # Red dot for both pupils\n",
    "    cv2.circle(frame, (left_pupil_x, left_pupil_y), 3, (0, 0, 255), -1)\n",
    "    cv2.circle(frame, (right_pupil_x, right_pupil_y), 3, (0, 0, 255), -1)\n",
    "\n",
    "    return baseline_position\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    global blink_detected, claw_state\n",
    "    blink_detected = False\n",
    "    claw_state = False\n",
    "    \n",
    "    # Initialize resources\n",
    "    arduino = initialize_serial('COM3')\n",
    "    face_mesh = initialize_face_mesh()\n",
    "    cap1 = cv2.VideoCapture(0)\n",
    "    cap2 = cv2.VideoCapture(1)\n",
    "    \n",
    "    baseline_position = None\n",
    "    movement_threshold = 0.01\n",
    "\n",
    "    while cap1.isOpened() and cap2.isOpened():\n",
    "        success1, frame1 = cap1.read()\n",
    "        success2, frame2 = cap2.read()\n",
    "        if not success1 or not success2:\n",
    "            print(\"Error reading frames.\")\n",
    "            break\n",
    "        \n",
    "        # Flip the frames horizontally for better visualization\n",
    "        frame1 = cv2.flip(frame1, 1)\n",
    "        frame2 = cv2.flip(frame2, 1)\n",
    "        \n",
    "        # Convert frames to RGB for processing\n",
    "        frame_rgb = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        results = face_mesh.process(frame_rgb)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                baseline_position = process_face_landmarks(face_landmarks, arduino, baseline_position, movement_threshold, frame1)\n",
    "\n",
    "        # Resize frames for better visualization\n",
    "        frame1_resized = cv2.resize(frame1, (640, 420))\n",
    "        frame2_resized = cv2.resize(frame2, (640, 420))\n",
    "\n",
    "        # Stack frames vertically\n",
    "        stacked_frame = np.vstack((frame1_resized, frame2_resized))\n",
    "\n",
    "        # Show the stacked frames with overlayed text\n",
    "        cv2.imshow(\"Feed\", stacked_frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap1.release()\n",
    "    cap2.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86501539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0732fbf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf95960b",
   "metadata": {},
   "source": [
    "### MEASURING RESPONSE TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef8f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Mediapipe FaceMesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Webcam capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Variables for gesture state\n",
    "blink_detected = False  # Tracks if blink was detected in the previous frame\n",
    "eyebrow_state = \"Neutral\"\n",
    "\n",
    "# Function to calculate the gaze direction\n",
    "def calculate_gaze_direction(iris_center, eye_corners):\n",
    "    left_corner = eye_corners[0]\n",
    "    right_corner = eye_corners[1]\n",
    "    horizontal_ratio = (iris_center.x - left_corner.x) / (right_corner.x - left_corner.x)\n",
    "    return horizontal_ratio\n",
    "\n",
    "# Function to calculate blinking\n",
    "def is_blinking(eye_landmarks, threshold=0.2):\n",
    "    top = np.array([eye_landmarks[1].x, eye_landmarks[1].y])\n",
    "    bottom = np.array([eye_landmarks[2].x, eye_landmarks[2].y])\n",
    "    left = np.array([eye_landmarks[0].x, eye_landmarks[0].y])\n",
    "    right = np.array([eye_landmarks[3].x, eye_landmarks[3].y])\n",
    "\n",
    "    vertical_distance = np.linalg.norm(top - bottom)\n",
    "    horizontal_distance = np.linalg.norm(left - right)\n",
    "\n",
    "    blink_ratio = vertical_distance / horizontal_distance\n",
    "    return blink_ratio < threshold\n",
    "\n",
    "# Function to calculate the eyebrow movement (detect upward movement only)\n",
    "def calculate_eyebrow_movement(landmarks, left_brow_indices, right_brow_indices, baseline, movement_threshold):\n",
    "    left_brow_y = np.mean([landmarks[i][1] for i in left_brow_indices])\n",
    "    right_brow_y = np.mean([landmarks[i][1] for i in right_brow_indices])\n",
    "    avg_brow_y = (left_brow_y + right_brow_y) / 2\n",
    "\n",
    "    if baseline is None:\n",
    "        baseline = avg_brow_y\n",
    "        return \"Neutral\", baseline\n",
    "\n",
    "    if avg_brow_y < baseline - movement_threshold:\n",
    "        return \"Up\", baseline\n",
    "    else:\n",
    "        baseline = 0.9 * baseline + 0.1 * avg_brow_y\n",
    "        return \"Neutral\", baseline\n",
    "\n",
    "# Function to process frames and measure gesture recognition time\n",
    "def process_gestures():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Initialize baseline and movement threshold for eyebrow detection\n",
    "    baseline_position = None\n",
    "    movement_threshold = 0.01\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        start_time = time.time()  # Start the timer when the frame is being processed\n",
    "        results = face_mesh.process(frame_rgb)\n",
    "        \n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                current_blink = False\n",
    "                eyebrow_state, baseline_position = calculate_eyebrow_movement(\n",
    "                    [(lm.x, lm.y, lm.z) for lm in face_landmarks.landmark],\n",
    "                    [46, 53, 52, 65, 55, 63, 105, 66, 107],  # Left eyebrow\n",
    "                    [276, 283, 282, 295, 285, 293, 334, 296, 336],  # Right eyebrow\n",
    "                    baseline_position,\n",
    "                    movement_threshold\n",
    "                )\n",
    "                \n",
    "                # Detect eye blinking\n",
    "                left_eye_landmarks = [\n",
    "                    face_landmarks.landmark[133],  # Left corner\n",
    "                    face_landmarks.landmark[159],  # Top\n",
    "                    face_landmarks.landmark[145],  # Bottom\n",
    "                    face_landmarks.landmark[33],   # Right corner\n",
    "                ]\n",
    "                right_eye_landmarks = [\n",
    "                    face_landmarks.landmark[362],  # Left corner\n",
    "                    face_landmarks.landmark[386],  # Top\n",
    "                    face_landmarks.landmark[374],  # Bottom\n",
    "                    face_landmarks.landmark[263],  # Right corner\n",
    "                ]\n",
    "                left_blinking = is_blinking(left_eye_landmarks)\n",
    "                right_blinking = is_blinking(right_eye_landmarks)\n",
    "                current_blink = left_blinking or right_blinking\n",
    "                \n",
    "                # Detect eye gaze direction\n",
    "                left_iris = face_landmarks.landmark[468]\n",
    "                right_iris = face_landmarks.landmark[473]\n",
    "                left_eye_corners = [face_landmarks.landmark[33], face_landmarks.landmark[133]]\n",
    "                right_eye_corners = [face_landmarks.landmark[362], face_landmarks.landmark[263]]\n",
    "\n",
    "                left_gaze_ratio = calculate_gaze_direction(left_iris, left_eye_corners)\n",
    "                right_gaze_ratio = calculate_gaze_direction(right_iris, right_eye_corners)\n",
    "                avg_gaze_ratio = (left_gaze_ratio + right_gaze_ratio) / 2\n",
    "\n",
    "                # Print out the gesture recognition results\n",
    "                if current_blink:\n",
    "                    print(\"Blink detected!\")\n",
    "                if eyebrow_state == \"Up\":\n",
    "                    print(\"Eyebrow raised!\")\n",
    "                if avg_gaze_ratio < 0.35:\n",
    "                    print(\"Looking left!\")\n",
    "                elif avg_gaze_ratio > 0.65:\n",
    "                    print(\"Looking right!\")\n",
    "                \n",
    "                # Calculate time taken for gesture detection and print the result\n",
    "                end_time = time.time()  # Capture the time after processing the gesture\n",
    "                gesture_recognition_time = end_time - start_time\n",
    "                print(f\"Gesture Recognition Time: {gesture_recognition_time:.4f} seconds\")\n",
    "\n",
    "                # Display on the frame\n",
    "                cv2.putText(frame, f\"Gaze: {'Left' if avg_gaze_ratio < 0.35 else 'Right' if avg_gaze_ratio > 0.65 else 'Center'}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"Blink: {'Detected' if current_blink else 'Not Detected'}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"Eyebrow: {eyebrow_state}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # Show the output frame with gestures detected\n",
    "        cv2.imshow(\"Gesture Recognition\", frame)\n",
    "\n",
    "        # Exit on pressing 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run the gesture processing function\n",
    "process_gestures()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688e3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0df52dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ce7e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16387e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b78665e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Initialize Mediapipe FaceMesh\n",
    "def initialize_face_mesh():\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    return mp_face_mesh.FaceMesh(refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Function to calculate gaze direction\n",
    "def calculate_gaze_direction(iris_center, eye_corners):\n",
    "    left_corner = eye_corners[0]\n",
    "    right_corner = eye_corners[1]\n",
    "    horizontal_ratio = (iris_center.x - left_corner.x) / (right_corner.x - left_corner.x)\n",
    "    return horizontal_ratio\n",
    "\n",
    "# Function to detect blinking\n",
    "def is_blinking(eye_landmarks, threshold=0.2):\n",
    "    top = np.array([eye_landmarks[1].x, eye_landmarks[1].y])\n",
    "    bottom = np.array([eye_landmarks[2].x, eye_landmarks[2].y])\n",
    "    left = np.array([eye_landmarks[0].x, eye_landmarks[0].y])\n",
    "    right = np.array([eye_landmarks[3].x, eye_landmarks[3].y])\n",
    "\n",
    "    vertical_distance = np.linalg.norm(top - bottom)\n",
    "    horizontal_distance = np.linalg.norm(left - right)\n",
    "\n",
    "    blink_ratio = vertical_distance / horizontal_distance\n",
    "    return blink_ratio < threshold\n",
    "\n",
    "# Function to overlay detection results\n",
    "def overlay_text(frame, text, position, color=(0, 255, 0)):\n",
    "    cv2.putText(frame, text, position, cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2, cv2.LINE_AA)\n",
    "\n",
    "# Function to process face landmarks\n",
    "def process_face_landmarks(face_landmarks, baseline_position, movement_threshold, frame, eye_closed_time):\n",
    "    global blink_detected, claw_state\n",
    "    \n",
    "    LEFT_BROW = [46, 53, 52, 65, 55, 63, 105, 66, 107]\n",
    "    RIGHT_BROW = [276, 283, 282, 295, 285, 293, 334, 296, 336]\n",
    "    \n",
    "    # Gaze detection\n",
    "    left_iris = face_landmarks.landmark[468]\n",
    "    right_iris = face_landmarks.landmark[473]\n",
    "    left_eye_corners = [face_landmarks.landmark[33], face_landmarks.landmark[133]]\n",
    "    right_eye_corners = [face_landmarks.landmark[362], face_landmarks.landmark[263]]\n",
    "    \n",
    "    avg_gaze_ratio = (calculate_gaze_direction(left_iris, left_eye_corners) +\n",
    "                      calculate_gaze_direction(right_iris, right_eye_corners)) / 2\n",
    "    gaze_direction = \"Center\"\n",
    "    if avg_gaze_ratio < 0.35:\n",
    "        gaze_direction = \"Left\"\n",
    "        gaze_color = (0, 0, 255)  # Red\n",
    "    elif avg_gaze_ratio > 0.65:\n",
    "        gaze_direction = \"Right\"\n",
    "        gaze_color = (0, 0, 255)  # Red\n",
    "    else:\n",
    "        gaze_color = (0, 255, 0)  # Green (default)\n",
    "    overlay_text(frame, f\"Gaze: {gaze_direction}\", (10, 30), gaze_color)\n",
    "\n",
    "    # Blink detection\n",
    "    left_eye_landmarks = [face_landmarks.landmark[133], face_landmarks.landmark[159], face_landmarks.landmark[145], face_landmarks.landmark[33]]\n",
    "    right_eye_landmarks = [face_landmarks.landmark[362], face_landmarks.landmark[386], face_landmarks.landmark[374], face_landmarks.landmark[263]]\n",
    "    current_blink = is_blinking(left_eye_landmarks) or is_blinking(right_eye_landmarks)\n",
    "    if current_blink and not blink_detected:\n",
    "        blink_detected = True\n",
    "    elif not current_blink:\n",
    "        blink_detected = False\n",
    "\n",
    "    # Track how long the eyes are closed for\n",
    "    if current_blink:\n",
    "        eye_closed_time += 1\n",
    "    else:\n",
    "        eye_closed_time = 0  # Reset the timer if eyes are open\n",
    "\n",
    "    # Stop the program if eyes are closed for more than a certain threshold (3 seconds or 90 frames)\n",
    "    if eye_closed_time > 90:  # 3 seconds at 30 FPS = 90 frames\n",
    "        print(\"Eyes closed for too long, exiting the program...\")\n",
    "        # Reset arm to initial position (send reset commands here)\n",
    "        send_reset_command()\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        exit()\n",
    "\n",
    "    return baseline_position, eye_closed_time\n",
    "\n",
    "# Function to send reset command to robot (example - you can adjust the actual control logic)\n",
    "def send_reset_command():\n",
    "    print(\"Resetting robot to initial position...\")\n",
    "    # Reset joint positions to their initial values\n",
    "    # Example: Reset the base, claw, shoulder, and elbow positions here.\n",
    "    # You could send reset commands or set variables to initial positions.\n",
    "    pass\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    global blink_detected, claw_state, eye_closed_time\n",
    "    blink_detected = False\n",
    "    claw_state = False\n",
    "    eye_closed_time = 0  # Timer for eye closure detection\n",
    "    \n",
    "    # Initialize resources\n",
    "    face_mesh = initialize_face_mesh()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    baseline_position = None\n",
    "    movement_threshold = 0.01\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print(\"Error reading frames.\")\n",
    "            break\n",
    "        \n",
    "        # Flip the frame horizontally for better visualization\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # Convert frames to RGB for processing\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        results = face_mesh.process(frame_rgb)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                baseline_position, eye_closed_time = process_face_landmarks(face_landmarks, baseline_position, movement_threshold, frame, eye_closed_time)\n",
    "\n",
    "        # Resize frames for better visualization\n",
    "        frame_resized = cv2.resize(frame, (640, 420))\n",
    "\n",
    "        # Show the frame with overlayed text\n",
    "        cv2.imshow(\"Feed\", frame_resized)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d97958b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
